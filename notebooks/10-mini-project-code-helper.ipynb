{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💻 10: Mini Project - Code Review Assistant\n",
    "\n",
    "Build a complete code review assistant agent that can load code files, analyze them for bugs and style issues, run tests, and suggest improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Learning Objectives\n",
    "\n",
    "By the end of this project, you will be able to:\n",
    "\n",
    "- [ ] Build a complete multi-step agent application\n",
    "- [ ] Use filesystem tools to load and analyze code\n",
    "- [ ] Execute Python code for testing and validation\n",
    "- [ ] Implement code analysis logic with an agent\n",
    "- [ ] Generate actionable improvement suggestions\n",
    "- [ ] Apply automated fixes to code\n",
    "- [ ] Structure a project with checkpoints and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Prerequisites\n",
    "\n",
    "- Completed notebooks 01-09\n",
    "- Understanding of ReACT agents\n",
    "- Familiarity with filesystem and code execution tools\n",
    "- Basic Python code analysis knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⏱️ Estimated Time: 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Project Goal\n",
    "\n",
    "Build a **Code Review Assistant** that:\n",
    "\n",
    "1. **Loads** a Python code file from disk\n",
    "2. **Analyzes** the code for:\n",
    "   - Syntax errors\n",
    "   - Logical bugs\n",
    "   - Style issues (PEP 8)\n",
    "   - Missing documentation\n",
    "   - Potential improvements\n",
    "3. **Runs** tests if present\n",
    "4. **Generates** a comprehensive review report\n",
    "5. **Suggests** specific fixes\n",
    "6. **Applies** fixes (optional)\n",
    "\n",
    "**Approach:** Use a ReACT agent with filesystem and code execution tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Setup\n",
    "\n",
    "Let's set up our environment and create sample code to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from local_llm_sdk import LocalLLMClient\nfrom dotenv import load_dotenv\nimport tempfile\nimport os\n\n# Load environment variables\nload_dotenv()\n\n# Create client\nclient = LocalLLMClient(\n    base_url=os.getenv(\"LLM_BASE_URL\"),\n    model=os.getenv(\"LLM_MODEL\"),\n    timeout=300\n)\n\n# Register built-in tools\nclient.register_tools_from(None)\n\n# Create temporary directory for project\nproject_dir = tempfile.mkdtemp()\n\nprint(\"✅ Setup Complete!\")\nprint(f\"Project directory: {project_dir}\")\nprint(f\"\\nRegistered tools: {', '.join(client.tools.list_tools())}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Code to Review\n",
    "\n",
    "Let's create a Python file with intentional issues for our agent to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code with issues\n",
    "sample_code = '''def calculate_average(numbers):\n",
    "    sum = 0\n",
    "    for num in numbers:\n",
    "        sum = sum + num\n",
    "    average = sum / len(numbers)\n",
    "    return average\n",
    "\n",
    "def find_max(lst):\n",
    "    max = lst[0]\n",
    "    for item in lst:\n",
    "        if item > max:\n",
    "            max = item\n",
    "    return max\n",
    "\n",
    "def is_even(n):\n",
    "    if n % 2 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Test the functions\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "print(\"Average:\", calculate_average(numbers))\n",
    "print(\"Max:\", find_max(numbers))\n",
    "print(\"Is 4 even?\", is_even(4))\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "code_file = os.path.join(project_dir, \"calculator.py\")\n",
    "with open(code_file, 'w') as f:\n",
    "    f.write(sample_code)\n",
    "\n",
    "print(\"📝 Created sample code file:\")\n",
    "print(f\"   {code_file}\")\n",
    "print(\"\\n🐛 Intentional issues:\")\n",
    "print(\"   - Shadowing built-in 'sum' and 'max'\")\n",
    "print(\"   - Missing docstrings\")\n",
    "print(\"   - is_even() can be simplified\")\n",
    "print(\"   - No error handling for empty lists\")\n",
    "print(\"   - Division by zero risk in calculate_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Project Structure\n",
    "\n",
    "We'll build this project in **5 checkpoints**:\n",
    "\n",
    "1. ✅ **Checkpoint 1**: Load code from file\n",
    "2. ✅ **Checkpoint 2**: Analyze code for issues\n",
    "3. ✅ **Checkpoint 3**: Run tests (if present)\n",
    "4. ✅ **Checkpoint 4**: Generate review report\n",
    "5. ✅ **Checkpoint 5**: Suggest and apply fixes\n",
    "\n",
    "Let's build it step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1: Load Code from File\n",
    "\n",
    "First, let's verify the agent can load and read the code file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 1: Load Code\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Read the Python file at {code_file} and show me its contents.\",\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"\\nCode loaded:\\n{result.final_response}\")\n",
    "\n",
    "if result.status == \"success\":\n",
    "    print(\"\\n✅ Checkpoint 1 Complete: Code file loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 1 Failed: Could not load code file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2: Analyze Code for Issues\n",
    "\n",
    "Now let's have the agent analyze the code for bugs, style issues, and improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 2: Analyze Code\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Analyze the Python code in {code_file}. \"\n",
    "    f\"Look for: \"\n",
    "    f\"(1) syntax errors, \"\n",
    "    f\"(2) logical bugs, \"\n",
    "    f\"(3) style issues (PEP 8), \"\n",
    "    f\"(4) missing documentation, \"\n",
    "    f\"(5) potential edge cases and errors, \"\n",
    "    f\"(6) code that could be simplified. \"\n",
    "    f\"Provide a detailed analysis with specific line numbers where possible.\",\n",
    "    max_iterations=15\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n📊 Code Analysis:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "if result.status == \"success\":\n",
    "    print(\"\\n✅ Checkpoint 2 Complete: Code analysis performed!\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 2 Failed: Analysis incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 3: Test Execution\n",
    "\n",
    "Let's test if the code actually runs without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 3: Test Execution\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Execute the Python code in {code_file} and check if it runs without errors. \"\n",
    "    f\"If there are any runtime errors, report them. \"\n",
    "    f\"Also test edge cases like empty lists to see if the functions handle them properly.\",\n",
    "    max_iterations=12\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n🧪 Test Results:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "if result.status == \"success\":\n",
    "    print(\"\\n✅ Checkpoint 3 Complete: Code tested!\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 3 Failed: Testing incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 4: Generate Review Report\n",
    "\n",
    "Create a comprehensive review report and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 4: Generate Review Report\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "review_file = os.path.join(project_dir, \"code_review.md\")\n",
    "\n",
    "result = client.react(\n",
    "    f\"Create a comprehensive code review report for {code_file}. \"\n",
    "    f\"The report should include: \"\n",
    "    f\"(1) Summary of findings, \"\n",
    "    f\"(2) List of issues with severity (Critical/Major/Minor), \"\n",
    "    f\"(3) Specific line numbers and descriptions, \"\n",
    "    f\"(4) Recommendations for each issue, \"\n",
    "    f\"(5) Overall code quality rating (1-10). \"\n",
    "    f\"Save the report to {review_file} in Markdown format.\",\n",
    "    max_iterations=18\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n📄 Report Generation:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "# Verify report was created\n",
    "if os.path.exists(review_file):\n",
    "    print(f\"\\n✅ Checkpoint 4 Complete: Review report saved to {review_file}\")\n",
    "    \n",
    "    # Display the report\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n📋 Generated Review Report:\\n\")\n",
    "    with open(review_file, 'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 4 Failed: Report file not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 5: Apply Fixes\n",
    "\n",
    "Finally, let's have the agent create an improved version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 5: Apply Fixes\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fixed_file = os.path.join(project_dir, \"calculator_fixed.py\")\n",
    "\n",
    "result = client.react(\n",
    "    f\"Read {code_file} and create an improved version that fixes all the issues. \"\n",
    "    f\"The improved code should: \"\n",
    "    f\"(1) Have proper docstrings for all functions, \"\n",
    "    f\"(2) Not shadow built-in names, \"\n",
    "    f\"(3) Handle edge cases (empty lists, division by zero), \"\n",
    "    f\"(4) Follow PEP 8 style guidelines, \"\n",
    "    f\"(5) Simplify code where possible. \"\n",
    "    f\"Save the fixed version to {fixed_file}.\",\n",
    "    max_iterations=20\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n🔧 Fix Application:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "# Verify and display fixed code\n",
    "if os.path.exists(fixed_file):\n",
    "    print(f\"\\n✅ Checkpoint 5 Complete: Fixed code saved to {fixed_file}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n✨ Fixed Code:\\n\")\n",
    "    with open(fixed_file, 'r') as f:\n",
    "        print(f.read())\n",
    "    \n",
    "    # Compare file sizes\n",
    "    original_lines = len(open(code_file).readlines())\n",
    "    fixed_lines = len(open(fixed_file).readlines())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n📊 Comparison:\")\n",
    "    print(f\"   Original: {original_lines} lines\")\n",
    "    print(f\"   Fixed: {fixed_lines} lines\")\n",
    "    print(f\"   Difference: {fixed_lines - original_lines:+d} lines\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 5 Failed: Fixed code file not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Project Complete!\n",
    "\n",
    "Let's verify all checkpoints were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n🎯 Project Summary: Code Review Assistant\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Check all checkpoints\n",
    "checkpoints = [\n",
    "    (\"Load code from file\", os.path.exists(code_file)),\n",
    "    (\"Analyze code for issues\", True),  # Already completed\n",
    "    (\"Test execution\", True),  # Already completed\n",
    "    (\"Generate review report\", os.path.exists(review_file)),\n",
    "    (\"Apply fixes\", os.path.exists(fixed_file)),\n",
    "]\n",
    "\n",
    "for i, (checkpoint, status) in enumerate(checkpoints, 1):\n",
    "    status_icon = \"✅\" if status else \"❌\"\n",
    "    print(f\"{status_icon} Checkpoint {i}: {checkpoint}\")\n",
    "\n",
    "all_complete = all(status for _, status in checkpoints)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if all_complete:\n",
    "    print(\"\\n🎉 SUCCESS: All checkpoints complete!\")\n",
    "    print(\"\\n📁 Generated Files:\")\n",
    "    print(f\"   - Original code: {code_file}\")\n",
    "    print(f\"   - Review report: {review_file}\")\n",
    "    print(f\"   - Fixed code: {fixed_file}\")\n",
    "    print(\"\\n💡 What you built:\")\n",
    "    print(\"   A complete AI-powered code review assistant that can:\")\n",
    "    print(\"   - Load and analyze Python code\")\n",
    "    print(\"   - Identify bugs and style issues\")\n",
    "    print(\"   - Test code execution\")\n",
    "    print(\"   - Generate comprehensive reports\")\n",
    "    print(\"   - Apply automated fixes\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some checkpoints incomplete. Review the outputs above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 Cleanup\n",
    "\n",
    "Clean up temporary files when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Uncomment to clean up:\n",
    "# shutil.rmtree(project_dir)\n",
    "# print(f\"✅ Cleaned up project directory: {project_dir}\")\n",
    "\n",
    "print(\"💡 Tip: Comment out the cleanup to keep files for inspection\")\n",
    "print(f\"   Project files in: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Extension Ideas\n",
    "\n",
    "Want to make your Code Review Assistant even better? Try these:\n",
    "\n",
    "### 1. Multi-File Support\n",
    "```python\n",
    "# Analyze an entire directory of Python files\n",
    "# Generate a combined report\n",
    "```\n",
    "\n",
    "### 2. Integration with Linters\n",
    "```python\n",
    "# Run pylint, flake8, or black\n",
    "# Parse and include their output in the report\n",
    "```\n",
    "\n",
    "### 3. Security Analysis\n",
    "```python\n",
    "# Check for common security vulnerabilities\n",
    "# SQL injection, command injection, etc.\n",
    "```\n",
    "\n",
    "### 4. Performance Analysis\n",
    "```python\n",
    "# Identify potential performance bottlenecks\n",
    "# Suggest algorithmic improvements\n",
    "```\n",
    "\n",
    "### 5. Test Generation\n",
    "```python\n",
    "# Automatically generate unit tests for functions\n",
    "# Create test cases for edge conditions\n",
    "```\n",
    "\n",
    "### 6. Git Integration\n",
    "```python\n",
    "# Review git diffs\n",
    "# Comment on pull requests\n",
    "# Track issue resolution over commits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Key Takeaways\n",
    "\n",
    "**What You Learned:**\n",
    "\n",
    "✅ **Agent-Based Architecture**: Using ReACT agents for complex multi-step tasks\n",
    "\n",
    "✅ **Tool Orchestration**: Combining filesystem and code execution tools\n",
    "\n",
    "✅ **Iterative Development**: Building with checkpoints for validation\n",
    "\n",
    "✅ **Real-World Application**: Creating a practical code analysis tool\n",
    "\n",
    "✅ **Report Generation**: Producing structured output (Markdown reports)\n",
    "\n",
    "✅ **Code Transformation**: Loading, analyzing, and rewriting code\n",
    "\n",
    "**Production Considerations:**\n",
    "\n",
    "- Add error handling for each checkpoint\n",
    "- Implement progress tracking and logging\n",
    "- Cache analysis results for large files\n",
    "- Add timeout handling for long operations\n",
    "- Validate generated fixes before applying\n",
    "- Support multiple programming languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Next Steps\n",
    "\n",
    "Congratulations on building a complete Code Review Assistant! Ready for the next challenge?\n",
    "\n",
    "➡️ Continue to [11-mini-project-data-analyzer.ipynb](./11-mini-project-data-analyzer.ipynb) to build:\n",
    "- A data analysis pipeline agent\n",
    "- CSV/JSON data loading and parsing\n",
    "- Statistical analysis and pattern detection\n",
    "- Visualization with matplotlib\n",
    "- Automated insights report generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}