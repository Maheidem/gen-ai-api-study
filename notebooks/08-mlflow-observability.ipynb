{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä 08: MLflow Observability\n",
    "\n",
    "Learn how to use MLflow tracing to observe, debug, and optimize your LLM applications with hierarchical execution traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- [ ] Install and configure MLflow for tracing\n",
    "- [ ] Start and access the MLflow UI\n",
    "- [ ] Enable automatic tracing in the Local LLM SDK\n",
    "- [ ] Understand hierarchical trace structure (CHAIN ‚Üí LLM ‚Üí AGENT ‚Üí TOOL)\n",
    "- [ ] View and analyze traces in the MLflow UI\n",
    "- [ ] Use traces for debugging complex agent workflows\n",
    "- [ ] Identify performance bottlenecks with trace timing data\n",
    "- [ ] Export and share traces for collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Prerequisites\n",
    "\n",
    "- Completed notebook 07 (ReACT Agents)\n",
    "- Understanding of agent execution flow\n",
    "- Familiarity with tools and multi-step tasks\n",
    "- LM Studio running with a model that supports function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Estimated Time: 20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ What is MLflow Tracing?\n",
    "\n",
    "**MLflow** is an open-source platform for managing ML workflows. **Tracing** is a feature that records the execution of your LLM applications.\n",
    "\n",
    "### Why Tracing?\n",
    "\n",
    "Without tracing:\n",
    "- ‚ùå Can't see what the agent did internally\n",
    "- ‚ùå Hard to debug when things go wrong\n",
    "- ‚ùå No visibility into performance bottlenecks\n",
    "- ‚ùå Difficult to optimize complex workflows\n",
    "\n",
    "With tracing:\n",
    "- ‚úÖ See every LLM call, tool execution, and decision\n",
    "- ‚úÖ Visualize hierarchical execution flow\n",
    "- ‚úÖ Measure timing for each component\n",
    "- ‚úÖ Debug issues by inspecting inputs/outputs at each step\n",
    "- ‚úÖ Compare different runs side-by-side\n",
    "\n",
    "### Hierarchical Trace Structure\n",
    "\n",
    "```\n",
    "CHAIN (top-level task)\n",
    "‚îú‚îÄ‚îÄ LLM (reasoning step 1)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ TOOL (calculator)\n",
    "‚îú‚îÄ‚îÄ LLM (reasoning step 2)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ TOOL (file_write)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ TOOL (file_read)\n",
    "‚îî‚îÄ‚îÄ LLM (reasoning step 3 - conclusion)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Installing MLflow\n",
    "\n",
    "First, let's install MLflow if it's not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow version: 3.4.0\n",
      "\n",
      "üí° MLflow 2.13+ is recommended for best tracing support\n"
     ]
    }
   ],
   "source": [
    "# Install MLflow (uncomment if needed)\n",
    "# !pip install mlflow>=2.13.0\n",
    "\n",
    "import mlflow\n",
    "\n",
    "print(f\"‚úÖ MLflow version: {mlflow.__version__}\")\n",
    "print(\"\\nüí° MLflow 2.13+ is recommended for best tracing support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Starting the MLflow UI\n",
    "\n",
    "The MLflow UI provides a visual interface for viewing traces.\n",
    "\n",
    "**Start MLflow UI in a terminal:**\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "```\n",
    "\n",
    "Then open your browser to: **http://localhost:5000**\n",
    "\n",
    "üí° **Tip**: Keep the MLflow UI open in a browser tab while running this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, start it from Python (in background):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/03 09:54:34 INFO mlflow.tracking.fluent: Experiment with name '08-mlflow-observability' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow tracking URI updated: file:///Users/maheidem/Documents/dev/gen-ai-api-study/mlruns\n",
      "\n",
      "üîç Current tracking URI: file:///Users/maheidem/Documents/dev/gen-ai-api-study/mlruns\n",
      "‚úÖ Experiment set: 08-mlflow-observability\n",
      "\n",
      "üí° Now run your agent tasks and check http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import ipynbname\n",
    "\n",
    "\n",
    "# Set tracking URI to project root (where MLflow UI is serving from)\n",
    "project_root = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "tracking_uri = f\"file://{project_root}/mlruns\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "print(f\"‚úÖ MLflow tracking URI updated: {tracking_uri}\")\n",
    "\n",
    "# Verify it's set correctly\n",
    "print(f\"\\nüîç Current tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Use the notebook filename to name the experiment so runs stay organized\n",
    "experiment_name = f\"{ipynbname.name()}\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"‚úÖ Experiment set: {experiment_name}\")\n",
    "print(\"\\nüí° Now run your agent tasks and check http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Enabling Automatic Tracing\n",
    "\n",
    "The Local LLM SDK has built-in MLflow tracing support!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Auto-detected model: qwen/qwen3-coder-30b\n",
      "‚úÖ Client created with MLflow tracing enabled!\n",
      "\n",
      "üí° All operations will now be traced automatically\n"
     ]
    }
   ],
   "source": [
    "from local_llm_sdk import LocalLLMClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create client with tracing enabled\n",
    "client = LocalLLMClient(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")\n",
    "\n",
    "# Register built-in tools\n",
    "client.register_tools_from(None)\n",
    "\n",
    "print(\"‚úÖ Client created with MLflow tracing enabled!\")\n",
    "print(\"\\nüí° All operations will now be traced automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Basic Trace Example\n",
    "\n",
    "Let's make a simple traced call and view it in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Response:\n",
      "12 multiplied by 15 is 180.\n",
      "\n",
      "‚úÖ This call was traced!\n",
      "\n",
      "üîç View the trace:\n",
      "   1. Go to http://localhost:5000\n",
      "   2. Click on 'Traces' in the sidebar\n",
      "   3. Find the most recent trace\n",
      "   4. Click to see the execution tree\n"
     ]
    }
   ],
   "source": [
    "# Simple chat with tracing\n",
    "response = client.chat(\"What is 12 multiplied by 15?\")\n",
    "\n",
    "print(\"üí¨ Response:\")\n",
    "print(response)\n",
    "print(\"\\n‚úÖ This call was traced!\")\n",
    "print(\"\\nüîç View the trace:\")\n",
    "print(\"   1. Go to http://localhost:5000\")\n",
    "print(\"   2. Click on 'Traces' in the sidebar\")\n",
    "print(\"   3. Find the most recent trace\")\n",
    "print(\"   4. Click to see the execution tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ What you'll see in MLflow UI:**\n",
    "\n",
    "- A `CHAIN` span for the overall chat call\n",
    "- An `LLM` span for the model inference\n",
    "- A `TOOL` span for the calculator tool\n",
    "- Input/output for each span\n",
    "- Timing information (duration in ms)\n",
    "- Token counts and other metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Grouping Related Calls with Conversation Context\n",
    "\n",
    "The most common MLflow anti-pattern: creating multiple separate traces when they should be grouped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Problem: Separate Traces\n",
    "\n",
    "Without grouping, each `client.chat()` call creates a separate top-level trace:\n",
    "\n",
    "```python\n",
    "# Creates trace #1\n",
    "response1 = client.chat(\"First question\")\n",
    "\n",
    "# Creates trace #2\n",
    "response2 = client.chat(\"Second question\")\n",
    "\n",
    "# Creates trace #3\n",
    "response3 = client.chat(\"Third question\")\n",
    "```\n",
    "\n",
    "**Result in MLflow UI:**\n",
    "- 3 separate traces\n",
    "- No visible relationship\n",
    "- Hard to analyze the workflow\n",
    "- Cluttered trace list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution: Use `client.conversation()`\n",
    "\n",
    "Wrap related calls in a conversation context:\n",
    "\n",
    "```python\n",
    "with client.conversation(\"my_workflow\"):\n",
    "    # All calls here become children of \"my_workflow\"\n",
    "    response1 = client.chat(\"First question\")\n",
    "    response2 = client.chat(\"Second question\")\n",
    "    response3 = client.chat(\"Third question\")\n",
    "```\n",
    "\n",
    "**Result in MLflow UI:**\n",
    "```\n",
    "my_workflow (parent trace)\n",
    "‚îú‚îÄ chat (first question)\n",
    "‚îú‚îÄ chat (second question)\n",
    "‚îî‚îÄ chat (third question)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Clear hierarchy showing the workflow\n",
    "- ‚úÖ Single trace to review\n",
    "- ‚úÖ Easy to see the complete interaction\n",
    "- ‚úÖ Better performance metrics (total time, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEMO: Grouped vs Ungrouped Traces\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ Ungrouped calls (3 separate traces):\n",
      "‚úÖ Check MLflow: 3 separate traces\n",
      "\n",
      "2Ô∏è‚É£ Grouped calls (1 parent trace):\n",
      "‚úÖ Check MLflow: 1 trace named 'math_workflow' with 3 children\n",
      "\n",
      "======================================================================\n",
      "üí° Open MLflow UI to see the difference!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DEMO: Grouped vs Ungrouped Traces\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Ungrouped (creates 3 separate traces)\n",
    "print(\"\\n1Ô∏è‚É£ Ungrouped calls (3 separate traces):\")\n",
    "client.chat(\"What is 5 + 5?\")\n",
    "client.chat(\"What is 10 * 2?\")\n",
    "client.chat(\"What is 20 / 4?\")\n",
    "print(\"‚úÖ Check MLflow: 3 separate traces\\n\")\n",
    "\n",
    "# Grouped (creates 1 parent trace with 3 children)\n",
    "print(\"2Ô∏è‚É£ Grouped calls (1 parent trace):\")\n",
    "with client.conversation(\"math_workflow\"):\n",
    "    client.chat(\"What is 5 + 5?\")\n",
    "    client.chat(\"What is 10 * 2?\")\n",
    "    client.chat(\"What is 20 / 4?\")\n",
    "print(\"‚úÖ Check MLflow: 1 trace named 'math_workflow' with 3 children\\n\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üí° Open MLflow UI to see the difference!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã When to Use Conversation Context\n",
    "\n",
    "**Use `conversation()` when:**\n",
    "- ‚úÖ Multiple calls that form a logical unit\n",
    "- ‚úÖ Multi-step workflows or pipelines\n",
    "- ‚úÖ Iterative processing (like agent loops)\n",
    "- ‚úÖ Debugging complex interactions\n",
    "\n",
    "**Don't use when:**\n",
    "- ‚ùå Single, independent chat calls\n",
    "- ‚ùå Unrelated queries\n",
    "- ‚ùå Each call needs separate metrics\n",
    "\n",
    "**Real-world examples:**\n",
    "```python\n",
    "# Example 1: Data analysis workflow\n",
    "with client.conversation(\"data_analysis\"):\n",
    "    summary = client.chat(\"Summarize this dataset\")\n",
    "    insights = client.chat(\"Find key insights\")\n",
    "    recommendations = client.chat(\"Suggest actions\")\n",
    "\n",
    "# Example 2: Code review workflow\n",
    "with client.conversation(\"code_review\"):\n",
    "    syntax = client.chat(\"Check syntax issues\")\n",
    "    style = client.chat(\"Review code style\")\n",
    "    security = client.chat(\"Identify security risks\")\n",
    "\n",
    "# Example 3: Agent pattern (agents do this automatically!)\n",
    "with client.conversation(\"react_agent_task\"):\n",
    "    for i in range(max_iterations):\n",
    "        response = client.chat(messages, use_tools=True)\n",
    "        # Agent logic...\n",
    "```\n",
    "\n",
    "**Pro tip:** The ReACT agent (`local_llm_sdk.agents.ReACT`) uses this pattern automatically! When you call `agent.run()`, all iterations are grouped under one parent trace. See `local_llm_sdk/agents/base.py:81` for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Agent Trace - The Full Picture\n",
    "\n",
    "Now let's trace a ReACT agent execution to see the complete hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ReACT Agent: Starting task\n",
      "Max iterations: 10\n",
      "Task: Calculate the factorial of 6, then convert the result to text, uppercase it, and count how many char...\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Iteration 1/10\n",
      "----------------------------------------\n",
      "Response: I got 720 as the factorial of 6. Now I'll convert this to text, uppercase it, and count the characters.\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 2/10\n",
      "----------------------------------------\n",
      "Response: The result is \"720\" (same as the original since it's numeric). Now I'll count the characters:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 3/10\n",
      "----------------------------------------\n",
      "Response: The factorial of 6 is 720. When converted to text and uppercased, it remains \"720\". This text has 3 characters.\n",
      "\n",
      "FINAL ANSWER: The factorial of 6 is 7...\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "================================================================================\n",
      "‚úì Task completed successfully in 3 iterations\n",
      "================================================================================\n",
      "ü§ñ Agent Result:\n",
      "Status: AgentStatus.SUCCESS\n",
      "Iterations: 3\n",
      "\n",
      "Final answer:\n",
      "The factorial of 6 is 720. When converted to text and uppercased, it remains \"720\". This text has 3 characters.\n",
      "\n",
      "FINAL ANSWER: The factorial of 6 is 720, which when converted to text and uppercased is \"720\" and has 3 characters.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üîç View the hierarchical trace in MLflow UI:\n",
      "   - CHAIN (agent.react)\n",
      "     ‚îú‚îÄ‚îÄ LLM (reasoning step 1)\n",
      "     ‚îÇ   ‚îî‚îÄ‚îÄ TOOL (execute_python for factorial)\n",
      "     ‚îú‚îÄ‚îÄ LLM (reasoning step 2)\n",
      "     ‚îÇ   ‚îî‚îÄ‚îÄ TOOL (text_transformer)\n",
      "     ‚îú‚îÄ‚îÄ LLM (reasoning step 3)\n",
      "     ‚îÇ   ‚îî‚îÄ‚îÄ TOOL (char_counter)\n",
      "     ‚îî‚îÄ‚îÄ LLM (final answer)\n"
     ]
    }
   ],
   "source": [
    "# Run an agent task with tracing\n",
    "result = client.react(\n",
    "    \"Calculate the factorial of 6, then convert the result to text, \"\n",
    "    \"uppercase it, and count how many characters it has.\",\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Agent Result:\")\n",
    "print(f\"Status: {result.status}\")\n",
    "print(f\"Iterations: {result.iterations}\")\n",
    "print(f\"\\nFinal answer:\\n{result.final_response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüîç View the hierarchical trace in MLflow UI:\")\n",
    "print(\"   - CHAIN (agent.react)\")\n",
    "print(\"     ‚îú‚îÄ‚îÄ LLM (reasoning step 1)\")\n",
    "print(\"     ‚îÇ   ‚îî‚îÄ‚îÄ TOOL (execute_python for factorial)\")\n",
    "print(\"     ‚îú‚îÄ‚îÄ LLM (reasoning step 2)\")\n",
    "print(\"     ‚îÇ   ‚îî‚îÄ‚îÄ TOOL (text_transformer)\")\n",
    "print(\"     ‚îú‚îÄ‚îÄ LLM (reasoning step 3)\")\n",
    "print(\"     ‚îÇ   ‚îî‚îÄ‚îÄ TOOL (char_counter)\")\n",
    "print(\"     ‚îî‚îÄ‚îÄ LLM (final answer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Understanding Span Types\n",
    "\n",
    "MLflow uses different span types to categorize operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span Type Reference\n",
    "\n",
    "| Span Type | Purpose | Examples |\n",
    "|-----------|---------|----------|\n",
    "| `CHAIN` | High-level workflow | `client.react()`, `client.chat()` |\n",
    "| `LLM` | Model inference | OpenAI/LM Studio API calls |\n",
    "| `AGENT` | Agent reasoning | ReACT loop iterations |\n",
    "| `TOOL` | Tool execution | `math_calculator`, `execute_python` |\n",
    "| `RETRIEVER` | Data retrieval | Database queries, API calls |\n",
    "\n",
    "### Trace Hierarchy\n",
    "\n",
    "```\n",
    "CHAIN (root span - entire workflow)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ AGENT (if using agents)\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ LLM (model call for reasoning)\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ attributes: model, temperature, tokens\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input: messages sent to model\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output: model response\n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ TOOL (tool execution)\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ attributes: tool name, parameters\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ input: tool arguments\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ output: tool result\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ Timing data for each span\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Complex Multi-Tool Trace\n",
    "\n",
    "Let's create a complex workflow to see a rich trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ReACT Agent: Starting task\n",
      "Max iterations: 15\n",
      "Task: Generate a Python list of the squares of numbers 1 through 10. Calculate the sum of all those square...\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Iteration 1/15\n",
      "----------------------------------------\n",
      "Response: Now I'll save this information to the specified file:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 2/15\n",
      "----------------------------------------\n",
      "Response: I see there's a syntax error with the f-strings in the Python command. Let me fix this by using a different approach:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 3/15\n",
      "----------------------------------------\n",
      "Response: The issue is with the f-string syntax in the Python command. Let me use a simpler approach with proper string formatting:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 4/15\n",
      "----------------------------------------\n",
      "Response: \n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 5/15\n",
      "----------------------------------------\n",
      "Response: Now I'll create the file with the content:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 6/15\n",
      "----------------------------------------\n",
      "Response: Let me create the file using a different approach with proper escaping:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 7/15\n",
      "----------------------------------------\n",
      "Response: Now let me read the file back and count the total characters:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 8/15\n",
      "----------------------------------------\n",
      "Response: Now I'll count the total characters in the file:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 9/15\n",
      "----------------------------------------\n",
      "Response: I have successfully completed all the required steps:\n",
      "\n",
      "1. Generated a Python list of squares from 1 to 10: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "2. C...\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "================================================================================\n",
      "‚úì Task completed successfully in 9 iterations\n",
      "================================================================================\n",
      "üéØ Complex Workflow Complete!\n",
      "\n",
      "Result: I have successfully completed all the required steps:\n",
      "\n",
      "1. Generated a Python list of squares from 1 to 10: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "2. Calculated the sum of all squares: 385\n",
      "3. Saved this information to /var/folders/br/8w257jc979z20gbrd0l_s6yh0000gn/T/tmp5be714tk/squares.txt\n",
      "4. Read the file back and counted the total characters: 57\n",
      "\n",
      "The file contains:\n",
      "\"Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Sum: 385\"\n",
      "\n",
      "Final answer: The total character count in the file is 57.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìä Trace Analysis in MLflow UI:\n",
      "\n",
      "1. Navigate to the Traces tab\n",
      "2. Find this trace (most recent)\n",
      "3. Expand the tree to see:\n",
      "   - Multiple LLM calls (one per reasoning step)\n",
      "   - execute_python span (generate squares & sum)\n",
      "   - filesystem_operation spans (write & read)\n",
      "   - char_counter span\n",
      "\n",
      "4. Click each span to inspect:\n",
      "   - Input parameters\n",
      "   - Output values\n",
      "   - Duration (ms)\n",
      "   - Timestamps\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Complex multi-tool task\n",
    "result = client.react(\n",
    "    f\"Generate a Python list of the squares of numbers 1 through 10. \"\n",
    "    f\"Calculate the sum of all those squares. \"\n",
    "    f\"Save the list and sum to {temp_dir}/squares.txt. \"\n",
    "    f\"Then read the file back and count the total characters in it.\",\n",
    "    max_iterations=15\n",
    ")\n",
    "\n",
    "print(\"üéØ Complex Workflow Complete!\")\n",
    "print(f\"\\nResult: {result.final_response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüìä Trace Analysis in MLflow UI:\")\n",
    "print(\"\\n1. Navigate to the Traces tab\")\n",
    "print(\"2. Find this trace (most recent)\")\n",
    "print(\"3. Expand the tree to see:\")\n",
    "print(\"   - Multiple LLM calls (one per reasoning step)\")\n",
    "print(\"   - execute_python span (generate squares & sum)\")\n",
    "print(\"   - filesystem_operation spans (write & read)\")\n",
    "print(\"   - char_counter span\")\n",
    "print(\"\\n4. Click each span to inspect:\")\n",
    "print(\"   - Input parameters\")\n",
    "print(\"   - Output values\")\n",
    "print(\"   - Duration (ms)\")\n",
    "print(\"   - Timestamps\")\n",
    "\n",
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Using Traces for Debugging\n",
    "\n",
    "Traces are invaluable when something goes wrong. Let's see how to debug with traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ReACT Agent: Starting task\n",
      "Max iterations: 8\n",
      "Task: Calculate the square root of -1 using Python, then tell me what type of number it is.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Iteration 1/8\n",
      "----------------------------------------\n",
      "Response: I see that the math module throws an error for negative numbers, but we can use the cmath module to handle complex numbers. Let me try that:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 2/8\n",
      "----------------------------------------\n",
      "Response: I've calculated the square root of -1 using Python's cmath module. The result is 1j, which is a complex number. The square root of -1 equals 1j, where...\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "================================================================================\n",
      "‚úì Task completed successfully in 2 iterations\n",
      "================================================================================\n",
      "üîç Debugging Example:\n",
      "\n",
      "Status: AgentStatus.SUCCESS\n",
      "\n",
      "Result:\n",
      "I've calculated the square root of -1 using Python's cmath module. The result is 1j, which is a complex number. The square root of -1 equals 1j, where j represents the imaginary unit. This is a fundamental concept in complex numbers, where the imaginary unit i (or j in engineering notation) is defined as the square root of -1. The result is a complex number with a real part of 0.0 and an imaginary part of 1.0.\n",
      "\n",
      "The square root of -1 is the imaginary unit j (or i in mathematics), which is a complex number, not a real number.\n",
      "\n",
      "FINAL ANSWER: The square root of -1 is 1j, which is a complex number (specifically an imaginary number).\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üõ†Ô∏è How to Debug with Traces:\n",
      "\n",
      "1. Open the trace in MLflow UI\n",
      "2. Look for spans with errors (red indicators)\n",
      "3. Check the execute_python span:\n",
      "   - Input: What code was executed?\n",
      "   - Output: What was the result/error?\n",
      "4. Trace the reasoning:\n",
      "   - Did the LLM handle complex numbers correctly?\n",
      "   - Did it import the 'cmath' module?\n",
      "5. Identify improvements:\n",
      "   - Better prompting?\n",
      "   - More specific tool instructions?\n",
      "   - Additional tools needed?\n"
     ]
    }
   ],
   "source": [
    "# A task that might have issues\n",
    "result = client.react(\n",
    "    \"Calculate the square root of -1 using Python, \"\n",
    "    \"then tell me what type of number it is.\",\n",
    "    max_iterations=8\n",
    ")\n",
    "\n",
    "print(\"üîç Debugging Example:\")\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"\\nResult:\\n{result.final_response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüõ†Ô∏è How to Debug with Traces:\")\n",
    "print(\"\\n1. Open the trace in MLflow UI\")\n",
    "print(\"2. Look for spans with errors (red indicators)\")\n",
    "print(\"3. Check the execute_python span:\")\n",
    "print(\"   - Input: What code was executed?\")\n",
    "print(\"   - Output: What was the result/error?\")\n",
    "print(\"4. Trace the reasoning:\")\n",
    "print(\"   - Did the LLM handle complex numbers correctly?\")\n",
    "print(\"   - Did it import the 'cmath' module?\")\n",
    "print(\"5. Identify improvements:\")\n",
    "print(\"   - Better prompting?\")\n",
    "print(\"   - More specific tool instructions?\")\n",
    "print(\"   - Additional tools needed?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Finding Performance Bottlenecks\n",
    "\n",
    "Use timing data in traces to optimize your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ReACT Agent: Starting task\n",
      "Max iterations: 12\n",
      "Task: Generate the first 20 prime numbers, then calculate statistical properties (mean, median, std dev), ...\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Iteration 1/12\n",
      "----------------------------------------\n",
      "Response: Now I have the first 20 prime numbers: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\n",
      "\n",
      "Next, I'll calculate the statisti...\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 2/12\n",
      "----------------------------------------\n",
      "Response: Now I'll sort the prime numbers in reverse order:\n",
      "\n",
      "\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "Iteration 3/12\n",
      "----------------------------------------\n",
      "Response: I've completed all the requested operations:\n",
      "\n",
      "1. Generated the first 20 prime numbers: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59...\n",
      "Tools used: 1\n",
      "  - bash\n",
      "\n",
      "================================================================================\n",
      "‚úì Task completed successfully in 3 iterations\n",
      "================================================================================\n",
      "‚ö° Performance Analysis:\n",
      "\n",
      "Total steps: 3\n",
      "Result: I've completed all the requested operations:\n",
      "\n",
      "1. Generated the first 20 prime numbers: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\n",
      "2. Calculated statistical properties...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìà Performance Optimization with Traces:\n",
      "\n",
      "1. Open trace in MLflow UI\n",
      "2. Sort spans by duration\n",
      "3. Identify slow operations:\n",
      "   - Which LLM calls took longest?\n",
      "   - Which tools were slowest?\n",
      "   - Are there redundant calls?\n",
      "\n",
      "4. Optimization strategies:\n",
      "   - Combine multiple tool calls into one\n",
      "   - Cache results of expensive operations\n",
      "   - Use faster models for simple reasoning\n",
      "   - Reduce max_steps if agent is over-thinking\n",
      "\n",
      "5. Compare before/after:\n",
      "   - Run optimized version\n",
      "   - Compare traces side-by-side\n",
      "   - Measure improvement\n"
     ]
    }
   ],
   "source": [
    "# Task with varying execution times\n",
    "result = client.react(\n",
    "    \"Generate the first 20 prime numbers, \"\n",
    "    \"then calculate statistical properties (mean, median, std dev), \"\n",
    "    \"and finally sort them in reverse order.\",\n",
    "    max_iterations=12\n",
    ")\n",
    "\n",
    "print(\"‚ö° Performance Analysis:\")\n",
    "print(f\"\\nTotal steps: {result.iterations}\")\n",
    "print(f\"Result: {result.final_response[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüìà Performance Optimization with Traces:\")\n",
    "print(\"\\n1. Open trace in MLflow UI\")\n",
    "print(\"2. Sort spans by duration\")\n",
    "print(\"3. Identify slow operations:\")\n",
    "print(\"   - Which LLM calls took longest?\")\n",
    "print(\"   - Which tools were slowest?\")\n",
    "print(\"   - Are there redundant calls?\")\n",
    "print(\"\\n4. Optimization strategies:\")\n",
    "print(\"   - Combine multiple tool calls into one\")\n",
    "print(\"   - Cache results of expensive operations\")\n",
    "print(\"   - Use faster models for simple reasoning\")\n",
    "print(\"   - Reduce max_steps if agent is over-thinking\")\n",
    "print(\"\\n5. Compare before/after:\")\n",
    "print(\"   - Run optimized version\")\n",
    "print(\"   - Compare traces side-by-side\")\n",
    "print(\"   - Measure improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Trace Metadata and Custom Attributes\n",
    "\n",
    "You can add custom metadata to traces for better organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Cannot set a deleted experiment 'Local LLM SDK Tutorial' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set run name and tags for better organization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLocal LLM SDK Tutorial\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_name=\u001b[33m\"\u001b[39m\u001b[33mfibonacci-research\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Tag the run\u001b[39;00m\n\u001b[32m      6\u001b[39m     mlflow.set_tag(\u001b[33m\"\u001b[39m\u001b[33mtask_type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmathematical_research\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/cc-sdk/lib/python3.12/site-packages/mlflow/tracking/fluent.py:211\u001b[39m, in \u001b[36mset_experiment\u001b[39m\u001b[34m(experiment_name, experiment_id)\u001b[39m\n\u001b[32m    205\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    206\u001b[39m                 message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExperiment with ID \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    207\u001b[39m                 error_code=RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    208\u001b[39m             )\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m experiment.lifecycle_stage != LifecycleStage.ACTIVE:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    212\u001b[39m             message=(\n\u001b[32m    213\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot set a deleted experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m as the active\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    214\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m experiment. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mYou can restore the experiment, or permanently delete the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mexperiment to create a new one.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    217\u001b[39m             ),\n\u001b[32m    218\u001b[39m             error_code=INVALID_PARAMETER_VALUE,\n\u001b[32m    219\u001b[39m         )\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _active_experiment_id\n\u001b[32m    222\u001b[39m _active_experiment_id = experiment.experiment_id\n",
      "\u001b[31mMlflowException\u001b[39m: Cannot set a deleted experiment 'Local LLM SDK Tutorial' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one."
     ]
    }
   ],
   "source": [
    "# Set run name and tags for better organization\n",
    "mlflow.set_experiment(\"Local LLM SDK Tutorial\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"fibonacci-research\") as run:\n",
    "    # Tag the run\n",
    "    mlflow.set_tag(\"task_type\", \"mathematical_research\")\n",
    "    mlflow.set_tag(\"complexity\", \"medium\")\n",
    "    \n",
    "    # Execute agent\n",
    "    result = client.react(\n",
    "        \"Calculate the first 10 Fibonacci numbers, \"\n",
    "        \"sum them, and determine if the sum is prime.\",\n",
    "        max_iterations=10\n",
    "    )\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"steps_taken\", result.iterations)\n",
    "    mlflow.log_metric(\"success\", 1 if result.status == \"success\" else 0)\n",
    "    \n",
    "    print(\"‚úÖ Trace logged with metadata!\")\n",
    "    print(f\"\\nRun ID: {run.info.run_id}\")\n",
    "    print(f\"Status: {result.status}\")\n",
    "    print(f\"\\nResult: {result.final_response}\")\n",
    "\n",
    "print(\"\\nüí° View in MLflow UI:\")\n",
    "print(\"   - Experiments tab: See all runs organized by experiment\")\n",
    "print(\"   - Filter by tags: complexity=medium\")\n",
    "print(\"   - Compare metrics across runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise: Trace Analysis Challenge\n",
    "\n",
    "**Challenge:** Create and analyze traces for a data processing pipeline.\n",
    "\n",
    "**Task:**\n",
    "1. Create an agent that processes a list of numbers\n",
    "2. The agent should:\n",
    "   - Generate 25 random numbers (1-100)\n",
    "   - Filter for even numbers only\n",
    "   - Calculate mean and median of even numbers\n",
    "   - Save results to a file\n",
    "   - Count characters in the saved file\n",
    "\n",
    "**Analysis Requirements:**\n",
    "1. Run the task and examine the trace in MLflow UI\n",
    "2. Count total spans in the trace\n",
    "3. Identify the slowest span\n",
    "4. Find how many tool calls were made\n",
    "5. Calculate total execution time\n",
    "\n",
    "Try it yourself first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Solution: Trace Analysis Challenge\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "results_file = os.path.join(temp_dir, \"even_numbers_analysis.txt\")\n",
    "\n",
    "print(\"üìä Data Processing Pipeline with Tracing\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Set up organized tracing\n",
    "mlflow.set_experiment(\"Data Processing Tutorial\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"even-numbers-pipeline\") as run:\n",
    "    # Tag for organization\n",
    "    mlflow.set_tag(\"pipeline_type\", \"data_processing\")\n",
    "    mlflow.set_tag(\"data_size\", \"25_numbers\")\n",
    "    \n",
    "    # Execute the pipeline\n",
    "    result = client.react(\n",
    "        f\"Generate 25 random integers between 1 and 100. \"\n",
    "        f\"Filter to keep only even numbers. \"\n",
    "        f\"Calculate the mean and median of the even numbers. \"\n",
    "        f\"Save all results (original list, even list, mean, median) to {results_file}. \"\n",
    "        f\"Then count how many characters are in that file.\",\n",
    "        max_iterations=15\n",
    "    )\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"steps_taken\", result.iterations)\n",
    "    mlflow.log_metric(\"success\", 1 if result.status == \"success\" else 0)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Pipeline Status: {result.status}\")\n",
    "    print(f\"Iterations: {result.iterations}\")\n",
    "    print(f\"\\nFinal Result:\\n{result.final_response}\")\n",
    "    \n",
    "    # Verify output file\n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        print(f\"\\nüìÑ Generated File ({len(content)} chars):\\n{content}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nüîç Trace Analysis Instructions:\\n\")\n",
    "    print(\"1. Open MLflow UI: http://localhost:5000\")\n",
    "    print(\"2. Navigate to 'Experiments' ‚Üí 'Data Processing Tutorial'\")\n",
    "    print(f\"3. Find run: 'even-numbers-pipeline' (ID: {run.info.run_id[:8]}...)\")\n",
    "    print(\"4. Click 'Traces' to view the execution tree\")\n",
    "    print(\"\\nüìä Analysis Tasks:\")\n",
    "    print(\"   ‚ñ° Count total spans (expand all nodes)\")\n",
    "    print(\"   ‚ñ° Identify slowest span (check duration column)\")\n",
    "    print(\"   ‚ñ° Count TOOL spans (how many tool calls?)\")\n",
    "    print(\"   ‚ñ° Note total execution time (root CHAIN span)\")\n",
    "    print(\"   ‚ñ° Inspect inputs/outputs of each span\")\n",
    "    print(\"\\nüí° Expected Observations:\")\n",
    "    print(\"   - Multiple LLM spans (one per reasoning step)\")\n",
    "    print(\"   - execute_python spans (random numbers, filtering, stats)\")\n",
    "    print(\"   - filesystem_operation spans (write and read)\")\n",
    "    print(\"   - char_counter span (final count)\")\n",
    "    print(\"   - Each span shows exact inputs and outputs\")\n",
    "    print(\"   - Duration shows which operations are slowest\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(temp_dir)\n",
    "print(\"\\n‚úÖ Analysis complete!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution cell (run to see answer)\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "results_file = os.path.join(temp_dir, \"even_numbers_analysis.txt\")\n",
    "\n",
    "print(\"üìä Data Processing Pipeline with Tracing\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mlflow.set_experiment(\"Data Processing Tutorial\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"even-numbers-pipeline\") as run:\n",
    "    mlflow.set_tag(\"pipeline_type\", \"data_processing\")\n",
    "    mlflow.set_tag(\"data_size\", \"25_numbers\")\n",
    "    \n",
    "    result = client.react(\n",
    "        f\"Generate 25 random integers between 1 and 100. \"\n",
    "        f\"Filter to keep only even numbers. \"\n",
    "        f\"Calculate the mean and median of the even numbers. \"\n",
    "        f\"Save all results (original list, even list, mean, median) to {results_file}. \"\n",
    "        f\"Then count how many characters are in that file.\",\n",
    "        max_iterations=15\n",
    "    )\n",
    "    \n",
    "    mlflow.log_metric(\"steps_taken\", result.iterations)\n",
    "    mlflow.log_metric(\"success\", 1 if result.status == \"success\" else 0)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Pipeline Status: {result.status}\")\n",
    "    print(f\"Iterations: {result.iterations}\")\n",
    "    print(f\"\\nFinal Result:\\n{result.final_response}\")\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        print(f\"\\nüìÑ Generated File ({len(content)} chars):\\n{content}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nüîç Trace Analysis Instructions:\\n\")\n",
    "    print(\"1. Open MLflow UI: http://localhost:5000\")\n",
    "    print(\"2. Navigate to 'Experiments' ‚Üí 'Data Processing Tutorial'\")\n",
    "    print(f\"3. Find run: 'even-numbers-pipeline' (ID: {run.info.run_id[:8]}...)\")\n",
    "    print(\"4. Click 'Traces' to view the execution tree\")\n",
    "    print(\"\\nüìä Analysis Tasks:\")\n",
    "    print(\"   ‚ñ° Count total spans (expand all nodes)\")\n",
    "    print(\"   ‚ñ° Identify slowest span (check duration column)\")\n",
    "    print(\"   ‚ñ° Count TOOL spans (how many tool calls?)\")\n",
    "    print(\"   ‚ñ° Note total execution time (root CHAIN span)\")\n",
    "    print(\"   ‚ñ° Inspect inputs/outputs of each span\")\n",
    "\n",
    "shutil.rmtree(temp_dir)\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Common Pitfalls\n",
    "\n",
    "### 1. Forgetting to Enable Tracing\n",
    "```python\n",
    "# ‚ùå Bad: Tracing not enabled\n",
    "client = LocalLLMClient(base_url=\"...\", model=\"...\")\n",
    "# No traces will be generated\n",
    "\n",
    "# ‚úÖ Good: Enable tracing\n",
    "client = LocalLLMClient(\n",
    "    base_url=\"...\",\n",
    "    model=\"...\",\n",
    "    enable_tracing=True\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. Not Starting MLflow UI\n",
    "```bash\n",
    "# ‚ö†Ô∏è Must start MLflow UI to view traces\n",
    "mlflow ui --port 5000\n",
    "\n",
    "# Then open http://localhost:5000\n",
    "```\n",
    "\n",
    "### 3. Overwhelming Trace Volume\n",
    "```python\n",
    "# ‚ö†Ô∏è Too many traces can clutter the UI\n",
    "for i in range(1000):\n",
    "    client.chat(f\"Task {i}\")  # Creates 1000 traces!\n",
    "\n",
    "# üí° Tip: Use experiments and tags to organize\n",
    "# üí° Tip: Disable tracing for production/bulk operations\n",
    "```\n",
    "\n",
    "### 4. Not Using Experiments\n",
    "```python\n",
    "# ‚ùå Bad: All traces in default experiment\n",
    "client.chat(\"Task 1\")\n",
    "client.chat(\"Task 2\")\n",
    "# Hard to find specific traces later\n",
    "\n",
    "# ‚úÖ Good: Organize with experiments\n",
    "mlflow.set_experiment(\"Tutorial Examples\")\n",
    "with mlflow.start_run(run_name=\"specific-task\"):\n",
    "    client.chat(\"Task\")\n",
    "```\n",
    "\n",
    "### 5. Ignoring Trace Insights\n",
    "```python\n",
    "# ‚ö†Ô∏è Don't just collect traces - analyze them!\n",
    "\n",
    "# Look for:\n",
    "# - Slow operations (optimize or cache)\n",
    "# - Redundant tool calls (combine operations)\n",
    "# - Error patterns (improve error handling)\n",
    "# - Token usage (optimize prompts)\n",
    "# - Reasoning quality (improve instructions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What You Learned\n",
    "\n",
    "‚úÖ **MLflow Setup**: Installing and starting the MLflow UI\n",
    "\n",
    "‚úÖ **Automatic Tracing**: Enabling tracing with `enable_tracing=True`\n",
    "\n",
    "‚úÖ **Hierarchical Traces**: Understanding CHAIN ‚Üí LLM ‚Üí AGENT ‚Üí TOOL structure\n",
    "\n",
    "‚úÖ **Trace Inspection**: Viewing inputs, outputs, and timing in MLflow UI\n",
    "\n",
    "‚úÖ **Debugging**: Using traces to understand what went wrong\n",
    "\n",
    "‚úÖ **Performance**: Identifying bottlenecks with timing data\n",
    "\n",
    "‚úÖ **Organization**: Using experiments, runs, and tags\n",
    "\n",
    "‚úÖ **Best Practices**: When and how to use tracing effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "You've mastered observability with MLflow! Now let's learn production-ready patterns.\n",
    "\n",
    "‚û°Ô∏è Continue to [09-production-patterns.ipynb](./09-production-patterns.ipynb) to learn:\n",
    "- Error handling and retry logic\n",
    "- Timeout configuration\n",
    "- Exponential backoff strategies\n",
    "- Environment-specific settings\n",
    "- Logging best practices\n",
    "- Building robust API wrappers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
