{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí≠ 03: Conversation History\n",
    "\n",
    "Learn how to maintain context across multiple messages to build natural, coherent conversations with your local LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- [ ] Build multi-turn conversations with context\n",
    "- [ ] Use `chat_with_history()` to maintain conversation state\n",
    "- [ ] Understand the role of message history in LLM responses\n",
    "- [ ] Recognize when context matters (and when it doesn't)\n",
    "- [ ] Manage conversation history efficiently\n",
    "- [ ] Build a complete Q&A session with memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Prerequisites\n",
    "\n",
    "- Completed notebook 02 (Basic Chat)\n",
    "- Understanding of system prompts and temperature\n",
    "- LM Studio running with a loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Estimated Time: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ The Problem: No Memory in Simple Chat\n",
    "\n",
    "Each `chat()` call is independent - the LLM doesn't remember previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Auto-detected model: qwen/qwen3-coder-30b\n",
      "Response 1: Hello Alice! It's nice to meet you. How can I help you today?\n",
      "\n",
      "Response 2: I don't have any information about your name. I don't retain personal information from our conversations, and I don't know who you are unless you tell me. Is there something specific you'd like to discuss or help with?\n"
     ]
    }
   ],
   "source": [
    "from local_llm_sdk import LocalLLMClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = LocalLLMClient(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")\n",
    "\n",
    "# First message\n",
    "response1 = client.chat(\"My name is Alice.\")\n",
    "print(\"Response 1:\", response1)\n",
    "\n",
    "# Second message - but the LLM won't remember!\n",
    "response2 = client.chat(\"What's my name?\")\n",
    "print(\"\\nResponse 2:\", response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùå The LLM can't remember your name because each call is independent!**\n",
    "\n",
    "Each `chat()` call creates a new conversation from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ The Solution: Conversation History\n",
    "\n",
    "Use `chat_with_history()` to maintain context across multiple turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1:\n",
      "You: My name is Alice.\n",
      "LLM: Hello Alice! It's nice to meet you. How can I help you today?\n",
      "\n",
      "Turn 2:\n",
      "You: What's my name?\n",
      "LLM: Your name is Alice, as you mentioned earlier. It was nice to meet you, Alice! Is there something I can help you with today?\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìö Conversation history now has 4 messages\n"
     ]
    }
   ],
   "source": [
    "# Start a conversation with history\n",
    "history = []\n",
    "\n",
    "# Turn 1: Introduce yourself\n",
    "response1, history = client.chat_with_history(\n",
    "    \"My name is Alice.\",\n",
    "    history\n",
    ")\n",
    "print(\"Turn 1:\")\n",
    "print(f\"You: My name is Alice.\")\n",
    "print(f\"LLM: {response1}\")\n",
    "\n",
    "# Turn 2: Ask about your name\n",
    "response2, history = client.chat_with_history(\n",
    "    \"What's my name?\",\n",
    "    history\n",
    ")\n",
    "print(\"\\nTurn 2:\")\n",
    "print(f\"You: What's my name?\")\n",
    "print(f\"LLM: {response2}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nüìö Conversation history now has {len(history)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚úÖ Now the LLM remembers!**\n",
    "\n",
    "The `chat_with_history()` method:\n",
    "1. Takes your new message\n",
    "2. Adds it to the conversation history\n",
    "3. Sends the full history to the LLM\n",
    "4. Returns both the response AND the updated history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Understanding Message History\n",
    "\n",
    "Let's peek inside the history to see what's actually stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Current conversation history:\n",
      "\n",
      "Message 1:\n",
      "  Role: user\n",
      "  Content: My name is Alice.\n",
      "\n",
      "Message 2:\n",
      "  Role: assistant\n",
      "  Content: Hello Alice! It's nice to meet you. How can I help you today?\n",
      "\n",
      "Message 3:\n",
      "  Role: user\n",
      "  Content: What's my name?\n",
      "\n",
      "Message 4:\n",
      "  Role: assistant\n",
      "  Content: Your name is Alice, as you mentioned earlier. It was nice to meet you, Alice! Is there something I can help you with today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\"üìù Current conversation history:\\n\")\n",
    "for i, message in enumerate(history, 1):\n",
    "    print(f\"Message {i}:\")\n",
    "    print(f\"  Role: {message.role}\")\n",
    "    print(f\"  Content: {message.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Message Structure:**\n",
    "\n",
    "Each message is a `ChatMessage` object with two key attributes:\n",
    "- `role`: Who sent the message (\"user\", \"assistant\", or \"system\")\n",
    "- `content`: The actual text of the message\n",
    "\n",
    "Access them using dot notation: `message.role` and `message.content`\n",
    "\n",
    "The conversation alternates: user ‚Üí assistant ‚Üí user ‚Üí assistant ‚Üí ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Building a Multi-Turn Conversation\n",
    "\n",
    "Let's have a real conversation with context building over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóæ Japan Travel Planning Conversation\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üë§ You: I'm planning a trip to Japan.\n",
      "ü§ñ LLM: That sounds exciting! Japan is a wonderful destination with so much to offer. Here are some key things to consider for your trip:\n",
      "\n",
      "**Best Time to Visit:**\n",
      "- Spring (March-May) for cherry blossoms\n",
      "- Autumn (September-November) for beautiful foliage\n",
      "- Winter for skiing and hot springs\n",
      "- Summer for festivals but it's hot and humid\n",
      "\n",
      "**Must-See Destinations:**\n",
      "- Tokyo (modern metropolis with amazing food)\n",
      "- Kyoto (traditional temples and gardens)\n",
      "- Osaka (food capital)\n",
      "- Hiroshima/Miyajima (history and nature)\n",
      "- Nara (ancient capital, friendly deer)\n",
      "\n",
      "**Practical Tips:**\n",
      "- Get a Japan Rail Pass for traveling between cities\n",
      "- Learn a few basic Japanese phrases\n",
      "- Carry cash (many places don't accept cards)\n",
      "- Download translation apps\n",
      "- Consider staying in ryokans (traditional inns) for unique experiences\n",
      "\n",
      "**What interests you most?** Food, culture, nature, urban exploration, or something else? I can give you more specific recommendations based on your preferences.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: What's the best time of year to visit?\n",
      "ü§ñ LLM: The best time depends on what you want to experience:\n",
      "\n",
      "**Spring (March-May)** - Most popular time\n",
      "- Cherry blossoms (hanami) peak varies by region\n",
      "- Mild, pleasant weather\n",
      "- Festivals and seasonal specialties\n",
      "- Busiest and most expensive\n",
      "\n",
      "**Autumn (September-November)** \n",
      "- Stunning fall foliage (k≈çy≈ç)\n",
      "- Comfortable temperatures\n",
      "- Great for hiking and scenic train rides\n",
      "- Good balance of weather and crowds\n",
      "\n",
      "**Winter (December-February)**\n",
      "- Perfect for skiing in Hokkaido and Nagano\n",
      "- Hot springs (onsen) experiences\n",
      "- Less crowded\n",
      "- Can be cold, especially in northern regions\n",
      "\n",
      "**Summer (June-August)**\n",
      "- Festivals and summer events\n",
      "- Hot and humid\n",
      "- Peak tourist season\n",
      "- Good for beach activities in Okinawa\n",
      "\n",
      "**My recommendation:** Spring (late March to early April) or Autumn (late October to early November) offer the best combination of good weather, fewer crowds, and beautiful scenery. Spring is particularly magical for cherry blossoms, while Autumn provides spectacular fall colors.\n",
      "\n",
      "What type of activities are you most interested in? That might help narrow down the best timing for your specific interests.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: I love food. What should I try?\n",
      "ü§ñ LLM: Japan's food scene is incredible! Here are must-try experiences:\n",
      "\n",
      "**Street Food & Casual Eats:**\n",
      "- **Takoyaki** (octopus balls) - Tokyo's famous street food\n",
      "- **Okonomiyaki** (savory pancake) - Hiroshima's specialty\n",
      "- **Yakitori** (grilled chicken skewers) - Perfect for evenings\n",
      "- **Taiyaki** (fish-shaped cake) - Sweet treat filled with red bean\n",
      "\n",
      "**Traditional Dishes:**\n",
      "- **Sushi** - Fresh fish at a good sushi bar\n",
      "- **Ramen** - Regional varieties (tonkotsu, shoyu, miso)\n",
      "- **Tempura** - Lightly battered and fried seafood/vegetables\n",
      "- **Kaiseki** - Traditional multi-course meal (for special occasions)\n",
      "\n",
      "**Regional Specialties:**\n",
      "- **Kushikatsu** (deep-fried skewers) - Osaka\n",
      "- **Monjayaki** (cooked pancake) - Hiroshima\n",
      "- **Soba/Udon** - Various regional noodle styles\n",
      "- **Fugu** (pufferfish) - For adventurous eaters (must be prepared by licensed chefs)\n",
      "\n",
      "**Must-Experience:**\n",
      "- **Izakaya** (pub-style dining) - Great for trying many small dishes\n",
      "- **Food markets** like Tsukiji Outer Market in Tokyo\n",
      "- **Local ramen shops** - Often family-run and authentic\n",
      "\n",
      "What type of dining experience appeals to you most? Casual street food, fine dining, or something in between?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: How much would typical street food cost?\n",
      "ü§ñ LLM: Street food in Japan is generally quite affordable:\n",
      "\n",
      "**Typical Street Food Prices:**\n",
      "- **Takoyaki**: 200-300 yen (~$1.50-2.50 USD)\n",
      "- **Yakitori**: 150-200 yen per skewer (~$1-1.50 USD)\n",
      "- **Taiyaki**: 100-150 yen (~$0.75-1.25 USD)\n",
      "- **Okonomiyaki**: 500-800 yen (~$3.50-6 USD) for a small portion\n",
      "- **Gyoza**: 150-200 yen per piece (~$1-1.50 USD)\n",
      "- **Corn dogs**: 200-300 yen (~$1.50-2.50 USD)\n",
      "\n",
      "**Average Daily Street Food Spending:**\n",
      "- **Budget**: 500-1,000 yen (~$3.50-7 USD) for a few snacks\n",
      "- **Moderate**: 1,000-2,000 yen (~$7-14 USD) for meals plus snacks\n",
      "- **Splurge**: 2,000+ yen (~$14+ USD) for multiple dishes\n",
      "\n",
      "**Money-Saving Tips:**\n",
      "- Eat at food courts (like in shopping malls)\n",
      "- Look for lunch specials (often 500-800 yen meals)\n",
      "- Try the \"takoyaki\" and \"yakitori\" stalls that serve multiple items\n",
      "- Avoid tourist-heavy areas where prices are higher\n",
      "\n",
      "Keep in mind that drinks (sake, beer, soft drinks) add about 300-500 yen per item, and you'll also want to budget for transportation. Overall, street food is very budget-friendly compared to sit-down restaurants!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: Can you summarize your travel advice for me?\n",
      "ü§ñ LLM: Here's a quick summary of my travel advice for Japan:\n",
      "\n",
      "**Best Time to Visit:**\n",
      "- Spring (late March-early April) or Autumn (late October-early November) for ideal weather and scenery\n",
      "\n",
      "**Key Destinations:**\n",
      "- Tokyo (modern city, amazing food)\n",
      "- Kyoto (traditional temples, culture)\n",
      "- Osaka (food capital)\n",
      "- Hiroshima/Miyajima (history, nature)\n",
      "\n",
      "**Food Highlights:**\n",
      "- Try street food: takoyaki, yakitori, okonomiyaki\n",
      "- Typical street food: 150-300 yen per item\n",
      "- Visit izakayas and food markets\n",
      "\n",
      "**Practical Tips:**\n",
      "- Get a Japan Rail Pass for travel\n",
      "- Learn basic Japanese phrases\n",
      "- Carry cash (many places don't accept cards)\n",
      "- Download translation apps\n",
      "\n",
      "**Budget Considerations:**\n",
      "- Street food is very affordable (500-2000 yen daily)\n",
      "- Meals at restaurants are more expensive but still reasonable\n",
      "- Consider staying in ryokans for unique experiences\n",
      "\n",
      "The key is balancing the amazing food scene with good timing and budgeting for transportation. What aspect of planning interests you most?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìö Final conversation: 10 messages total\n"
     ]
    }
   ],
   "source": [
    "# Start fresh\n",
    "history = []\n",
    "\n",
    "# Define a conversation\n",
    "conversation = [\n",
    "    \"I'm planning a trip to Japan.\",\n",
    "    \"What's the best time of year to visit?\",\n",
    "    \"I love food. What should I try?\",\n",
    "    \"How much would typical street food cost?\",\n",
    "    \"Can you summarize your travel advice for me?\"\n",
    "]\n",
    "\n",
    "print(\"üóæ Japan Travel Planning Conversation\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for user_message in conversation:\n",
    "    # Send message with history\n",
    "    response, history = client.chat_with_history(\n",
    "        user_message,\n",
    "        history\n",
    "    )\n",
    "    \n",
    "    # Display the exchange\n",
    "    print(f\"üë§ You: {user_message}\")\n",
    "    print(f\"ü§ñ LLM: {response}\")\n",
    "    print(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"\\nüìö Final conversation: {len(history)} messages total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Notice how the LLM:**\n",
    "- Remembers you're planning a Japan trip\n",
    "- Connects your love of food to restaurant recommendations\n",
    "- Provides cost estimates in context of food discussion\n",
    "- Summarizes the entire conversation at the end\n",
    "\n",
    "This is only possible because we maintained the conversation history!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ When Context Matters (and When It Doesn't)\n",
    "\n",
    "Context is important for some tasks but unnecessary for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WHEN CONTEXT MATTERS:\n",
      "\n",
      "You: I need a function to process data.\n",
      "LLM: I'd be happy to help you create a data processing function! However, I need a bit more information t...\n",
      "\n",
      "You: It should handle CSV files.\n",
      "LLM: Here's a comprehensive CSV processing function in Python:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import nump...\n",
      "\n",
      "You: And it needs to filter rows where age > 18.\n",
      "LLM: Here's the updated CSV processing function with age filtering:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from t...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "‚ùå WHEN CONTEXT DOESN'T MATTER:\n",
      "\n",
      "Q: What is the capital of France?\n",
      "A: The capital of France is Paris.\n",
      "\n",
      "Q: What is 25 * 4?\n",
      "A: 25 * 4 = 100\n",
      "\n",
      "Q: Translate 'hello' to Spanish.\n",
      "A: 'Hello' translated to Spanish is 'hola'.\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ WHEN CONTEXT MATTERS:\\n\")\n",
    "\n",
    "# Example: Refining requirements\n",
    "history = []\n",
    "\n",
    "msg1 = \"I need a function to process data.\"\n",
    "resp1, history = client.chat_with_history(msg1, history)\n",
    "print(f\"You: {msg1}\")\n",
    "print(f\"LLM: {resp1[:100]}...\\n\")\n",
    "\n",
    "msg2 = \"It should handle CSV files.\"\n",
    "resp2, history = client.chat_with_history(msg2, history)\n",
    "print(f\"You: {msg2}\")\n",
    "print(f\"LLM: {resp2[:100]}...\\n\")\n",
    "\n",
    "msg3 = \"And it needs to filter rows where age > 18.\"\n",
    "resp3, history = client.chat_with_history(msg3, history)\n",
    "print(f\"You: {msg3}\")\n",
    "print(f\"LLM: {resp3[:100]}...\\n\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(\"‚ùå WHEN CONTEXT DOESN'T MATTER:\\n\")\n",
    "\n",
    "# Example: Independent factual queries\n",
    "fact1 = client.chat(\"What is the capital of France?\")\n",
    "print(f\"Q: What is the capital of France?\")\n",
    "print(f\"A: {fact1}\\n\")\n",
    "\n",
    "fact2 = client.chat(\"What is 25 * 4?\")\n",
    "print(f\"Q: What is 25 * 4?\")\n",
    "print(f\"A: {fact2}\\n\")\n",
    "\n",
    "fact3 = client.chat(\"Translate 'hello' to Spanish.\")\n",
    "print(f\"Q: Translate 'hello' to Spanish.\")\n",
    "print(f\"A: {fact3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Use context when:**\n",
    "- Building on previous responses\n",
    "- Refining requirements or ideas\n",
    "- Having natural conversations\n",
    "- Working on a single topic over multiple turns\n",
    "- When \"it\" or \"that\" refers to earlier messages\n",
    "\n",
    "**üí° Skip context when:**\n",
    "- Asking independent factual questions\n",
    "- Performing simple calculations\n",
    "- Doing batch operations on unrelated items\n",
    "- Testing different prompts on the same task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Managing History: System Prompts\n",
    "\n",
    "You can include a system prompt when starting a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1:\n",
      "A list comprehension is a concise way to create lists in Python. It allows you to generate a new list by applying an expression to each item in an existing iterable (like a list, tuple, or range), optionally filtering items with a condition.\n",
      "\n",
      "## Basic Syntax\n",
      "```python\n",
      "[expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "## Examples\n",
      "\n",
      "### Simple List Comprehension\n",
      "```python\n",
      "# Create a list of squares\n",
      "squares = [x**2 for x in range(5)]\n",
      "print(squares)  # [0, 1, 4, 9, 16]\n",
      "\n",
      "# Create a list of even numbers\n",
      "evens = [x for x in range(10) if x % 2 == 0]\n",
      "print(evens)  # [0, 2, 4, 6, 8]\n",
      "```\n",
      "\n",
      "### With Strings\n",
      "```python\n",
      "# Convert strings to uppercase\n",
      "words = ['hello', 'world', 'python']\n",
      "uppercase = [word.upper() for word in words]\n",
      "print(uppercase)  # ['HELLO', 'WORLD', 'PYTHON']\n",
      "\n",
      "# Extract first letter of each word\n",
      "first_letters = [word[0] for word in words]\n",
      "print(first_letters)  # ['h', 'w', 'p']\n",
      "```\n",
      "\n",
      "### Nested List Comprehension\n",
      "```python\n",
      "# Create a matrix\n",
      "matrix = [[i*j for j in range(3)] for i in range(3)]\n",
      "print(matrix)  # [[0, 0, 0], [0, 1, 2], [0, 2, 4]]\n",
      "```\n",
      "\n",
      "## Benefits\n",
      "- **More readable** than traditional loops\n",
      "- **More concise** than using `map()` or `filter()`\n",
      "- **Often faster** than equivalent for loops\n",
      "- **Pythonic** - follows Python's philosophy of clean, readable code\n",
      "\n",
      "## Comparison with Traditional Loop\n",
      "```python\n",
      "# Traditional way\n",
      "squares = []\n",
      "for x in range(5):\n",
      "    squares.append(x**2)\n",
      "\n",
      "# List comprehension (equivalent)\n",
      "squares = [x**2 for x in range(5)]\n",
      "```\n",
      "\n",
      "List comprehensions are one of Python's most beloved features, making code more expressive and easier to understand.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Turn 2:\n",
      "Here's a more complex example that demonstrates multiple advanced features of list comprehensions:\n",
      "\n",
      "```python\n",
      "# Complex example: Processing student data\n",
      "students = [\n",
      "    {'name': 'Alice', 'grades': [85, 92, 78, 96], 'age': 20},\n",
      "    {'name': 'Bob', 'grades': [76, 81, 89, 73], 'age': 22},\n",
      "    {'name': 'Charlie', 'grades': [95, 98, 92, 88], 'age': 21},\n",
      "    {'name': 'Diana', 'grades': [88, 94, 85, 91], 'age': 20}\n",
      "]\n",
      "\n",
      "# 1. Get names of students with average grade > 85\n",
      "high_performers = [student['name'] for student in students \n",
      "                   if sum(student['grades']) / len(student['grades']) > 85]\n",
      "print(\"High performers:\", high_performers)  # ['Alice', 'Bob', 'Charlie', 'Diana']\n",
      "\n",
      "# 2. Get all grades above 90, flattened into single list\n",
      "high_grades = [grade for student in students \n",
      "               for grade in student['grades'] \n",
      "               if grade > 90]\n",
      "print(\"High grades:\", high_grades)  # [85, 92, 96, 81, 89, 95, 98, 92, 88, 94, 91]\n",
      "\n",
      "# 3. Create a list of tuples (name, average_grade) for students over 20\n",
      "student_averages = [(student['name'], sum(student['grades']) / len(student['grades'])) \n",
      "                   for student in students \n",
      "                   if student['age'] > 20]\n",
      "print(\"Students over 20:\", student_averages)  # [('Bob', 80.5), ('Charlie', 92.25)]\n",
      "\n",
      "# 4. Create a dictionary-like structure with nested comprehension\n",
      "grade_distribution = {\n",
      "    student['name']: [grade for grade in student['grades'] if grade >= 90]\n",
      "    for student in students\n",
      "}\n",
      "print(\"Grade distribution (90+):\", grade_distribution)\n",
      "# {'Alice': [85, 92, 96], 'Bob': [81, 89], 'Charlie': [95, 98, 92], 'Diana': [94, 91]}\n",
      "\n",
      "# 5. Complex transformation: Create formatted strings with conditions\n",
      "formatted_report = [\n",
      "    f\"{student['name']}: Avg={sum(student['grades'])/len(student['grades']):.1f} - {'Excellent' if sum(student['grades'])/len(student['grades']) >= 90 else 'Good'}\"\n",
      "    for student in students\n",
      "    if len(student['grades']) > 0  # Filter out empty grade lists\n",
      "]\n",
      "print(\"\\nFormatted report:\")\n",
      "for report in formatted_report:\n",
      "    print(report)\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "High performers: ['Alice', 'Bob', 'Charlie', 'Diana']\n",
      "High grades: [85, 92, 96, 81, 89, 95, 98, 92, 88, 94, 91]\n",
      "Students over 20: [('Bob', 80.5), ('Charlie', 92.25)]\n",
      "Grade distribution (90+): {'Alice': [85, 92, 96], 'Bob': [81, 89], 'Charlie': [95, 98, 92], 'Diana': [94, 91]}\n",
      "\n",
      "Formatted report:\n",
      "Alice: Avg=88.5 - Good\n",
      "Bob: Avg=80.5 - Good\n",
      "Charlie: Avg=92.2 - Excellent\n",
      "Diana: Avg=89.5 - Good\n",
      "```\n",
      "\n",
      "This example shows:\n",
      "- **Nested comprehensions** (iterating through lists within lists)\n",
      "- **Conditional filtering** with `if` clauses\n",
      "- **Complex expressions** with calculations and formatting\n",
      "- **Multiple conditions** and data transformations\n",
      "- **Dictionary comprehension** with list comprehension inside\n",
      "- **Chained operations** like calculating averages and applying conditions\n",
      "\n",
      "List comprehensions can handle quite sophisticated logic while remaining readable and efficient!\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìù History structure:\n",
      "  - user: What is a list comprehension?...\n",
      "  - assistant: A list comprehension is a concise way to create li...\n",
      "  - user: Show me a more complex example....\n",
      "  - assistant: Here's a more complex example that demonstrates mu...\n"
     ]
    }
   ],
   "source": [
    "# Start with a system prompt\n",
    "history = []\n",
    "system_prompt = \"You are a helpful Python tutor who explains concepts simply with code examples.\"\n",
    "\n",
    "# First message - include system prompt\n",
    "response1, history = client.chat_with_history(\n",
    "    \"What is a list comprehension?\",\n",
    "    history,\n",
    "    system=system_prompt\n",
    ")\n",
    "print(\"Turn 1:\")\n",
    "print(response1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Subsequent messages - no need to repeat system prompt!\n",
    "response2, history = client.chat_with_history(\n",
    "    \"Show me a more complex example.\",\n",
    "    history\n",
    ")\n",
    "print(\"Turn 2:\")\n",
    "print(response2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "print(\"üìù History structure:\")\n",
    "for msg in history:\n",
    "    print(f\"  - {msg.role}: {msg.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Important:** Only include `system` parameter on the FIRST call. The system message becomes part of the history and persists automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Advanced: Inspecting and Modifying History\n",
    "\n",
    "You can manually inspect or modify the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original response: Based on what you've told me so far, your favorites are:\n",
      "\n",
      "- **Color**: Blue\n",
      "- **Food**: Pizza\n",
      "\n",
      "You've shared these two preferences with me, so those are definitely your current favorites! Is there anything else you'd like to share about what you like, or perhaps other favorites you haven't mentioned yet?\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Response with modified history: Based on what you've told me so far, your favorites are:\n",
      "\n",
      "- **Color**: Blue\n",
      "- **Food**: Pizza\n",
      "\n",
      "Those are the two specific favorites you've mentioned to me. Is there anything else you'd like to share about your preferences?\n",
      "\n",
      "üí° Now it only remembers your color preference!\n"
     ]
    }
   ],
   "source": [
    "# Start a conversation\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"My favorite color is blue.\", history)\n",
    "response, history = client.chat_with_history(\"My favorite food is pizza.\", history)\n",
    "response, history = client.chat_with_history(\"What are my favorites?\", history)\n",
    "\n",
    "print(\"Original response:\", response)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Manually remove the food preference from history\n",
    "# (Keep only system, first user msg, first assistant msg, and last question)\n",
    "modified_history = [history[0], history[1], history[-1]]\n",
    "\n",
    "# Ask again with modified history\n",
    "response2, _ = client.chat_with_history(\n",
    "    \"What are my favorites?\",\n",
    "    modified_history\n",
    ")\n",
    "\n",
    "print(\"Response with modified history:\", response2)\n",
    "print(\"\\nüí° Now it only remembers your color preference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è Advanced technique:** Manually editing history is useful for:\n",
    "- Removing sensitive information\n",
    "- Keeping only relevant context (token optimization)\n",
    "- Correcting mistakes in the conversation\n",
    "- Implementing sliding window context (keep last N messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise: Build a Quiz Game\n",
    "\n",
    "**Challenge:** Create a Q&A quiz session where:\n",
    "1. The LLM asks you 3 trivia questions (one at a time)\n",
    "2. You provide answers\n",
    "3. The LLM evaluates each answer\n",
    "4. At the end, the LLM summarizes your score\n",
    "\n",
    "Requirements:\n",
    "- Use `chat_with_history()` to maintain context\n",
    "- Use a system prompt to make the LLM a quiz host\n",
    "- Must have at least 5+ turns (intro, Q1, A1, Q2, A2, Q3, A3, summary)\n",
    "\n",
    "Try it yourself first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Solution: Quiz game with conversation history\n",
    "\n",
    "history = []\n",
    "system_prompt = \"\"\"\n",
    "You are a friendly quiz show host. Ask the user 3 trivia questions, one at a time.\n",
    "After each answer, tell them if they're correct and give the right answer if they're wrong.\n",
    "After all 3 questions, summarize their score.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéÆ TRIVIA QUIZ GAME\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start the quiz\n",
    "response, history = client.chat_with_history(\n",
    "    \"Let's start the quiz!\",\n",
    "    history,\n",
    "    system=system_prompt\n",
    ")\n",
    "print(f\"üé§ Host: {response}\\n\")\n",
    "\n",
    "# User answers (you can modify these)\n",
    "answers = [\n",
    "    \"Paris\",           # If question is about France's capital\n",
    "    \"I don't know\",    # Skip a question\n",
    "    \"42\"               # Random guess\n",
    "]\n",
    "\n",
    "for i, answer in enumerate(answers, 1):\n",
    "    # Provide answer\n",
    "    print(f\"üë§ You: {answer}\")\n",
    "    response, history = client.chat_with_history(answer, history)\n",
    "    print(f\"üé§ Host: {response}\\n\")\n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "\n",
    "# Get final summary\n",
    "if \"score\" not in response.lower() and \"how did\" not in response.lower():\n",
    "    response, history = client.chat_with_history(\n",
    "        \"Can you tell me my final score?\",\n",
    "        history\n",
    "    )\n",
    "    print(f\"üë§ You: Can you tell me my final score?\")\n",
    "    print(f\"üé§ Host: {response}\")\n",
    "\n",
    "print(f\"\\n\\nüìä Total conversation turns: {len(history)}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ TRIVIA QUIZ GAME\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üé§ Host: Great! I'm ready for the quiz. Please go ahead and ask your first question! üöÄ\n",
      "\n",
      "üë§ You: Paris\n",
      "üé§ Host: Hello! You've mentioned \"Paris\" - are you looking for information about:\n",
      "\n",
      "- The city of Paris, France?\n",
      "- Something specific about Paris (like its landmarks, history, culture, etc.)?\n",
      "- Or perhaps you're thinking of a quiz question that starts with \"Paris\"?\n",
      "\n",
      "I'm ready to help with whatever you'd like to explore about Paris! üá´üá∑‚ú®\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: I don't know\n",
      "üé§ Host: No worries! Let me give you a quick quiz to get us started:\n",
      "\n",
      "**Question 1: What is the capital city of France?**\n",
      "\n",
      "A) Lyon\n",
      "B) Marseille\n",
      "C) Paris\n",
      "D) Nice\n",
      "\n",
      "Take your time to think about it! üòä\n",
      "\n",
      "(If you want to start over or try a different topic, just let me know!)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: 42\n",
      "üé§ Host: 42! That's a classic answer, especially if you were thinking of \"The Hitchhiker's Guide to the Galaxy\" where 42 is the \"Answer to the Ultimate Question of Life, the Universe, and Everything\"!\n",
      "\n",
      "But since we're doing a quiz, let me ask you:\n",
      "\n",
      "**Question 1: What is the capital city of France?**\n",
      "\n",
      "A) Lyon\n",
      "B) Marseille\n",
      "C) Paris\n",
      "D) Nice\n",
      "\n",
      "What's your answer? ü§î\n",
      "\n",
      "(Or if you were just testing me, that's okay too - 42 is a perfectly valid response in some contexts!)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: Can you tell me my final score?\n",
      "üé§ Host: I don't have any record of previous questions or answers from our conversation, so I can't calculate a final score. \n",
      "\n",
      "I only see that we've been going back and forth with \"Paris\" and \"42\" so far, but I don't have any quiz questions or answers to tally up.\n",
      "\n",
      "If you'd like to take a proper quiz with questions and answers that I can track, I'd be happy to start over with a new quiz where I can keep track of your responses!\n",
      "\n",
      "Would you like to start a new quiz? üéØ\n",
      "\n",
      "\n",
      "üìä Total conversation turns: 10\n"
     ]
    }
   ],
   "source": [
    "# Solution cell (run this to see the answer)\n",
    "history = []\n",
    "system_prompt = \"\"\"\n",
    "You are a friendly quiz show host. Ask the user 3 trivia questions, one at a time.\n",
    "After each answer, tell them if they're correct and give the right answer if they're wrong.\n",
    "After all 3 questions, summarize their score.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéÆ TRIVIA QUIZ GAME\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start the quiz\n",
    "response, history = client.chat_with_history(\n",
    "    \"Let's start the quiz!\",\n",
    "    history,\n",
    "    system=system_prompt\n",
    ")\n",
    "print(f\"üé§ Host: {response}\\n\")\n",
    "\n",
    "# User answers (you can modify these)\n",
    "answers = [\n",
    "    \"Paris\",\n",
    "    \"I don't know\",\n",
    "    \"42\"\n",
    "]\n",
    "\n",
    "for i, answer in enumerate(answers, 1):\n",
    "    print(f\"üë§ You: {answer}\")\n",
    "    response, history = client.chat_with_history(answer, history)\n",
    "    print(f\"üé§ Host: {response}\\n\")\n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "\n",
    "# Get final summary\n",
    "if \"score\" not in response.lower() and \"how did\" not in response.lower():\n",
    "    response, history = client.chat_with_history(\n",
    "        \"Can you tell me my final score?\",\n",
    "        history\n",
    "    )\n",
    "    print(f\"üë§ You: Can you tell me my final score?\")\n",
    "    print(f\"üé§ Host: {response}\")\n",
    "\n",
    "print(f\"\\n\\nüìä Total conversation turns: {len(history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Common Pitfalls\n",
    "\n",
    "### 1. Forgetting to Update History\n",
    "```python\n",
    "# ‚ùå Bad: Not using the returned history\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"Hello\", history)\n",
    "response, _ = client.chat_with_history(\"What did I just say?\", history)  # Wrong!\n",
    "# The second message won't remember \"Hello\"\n",
    "\n",
    "# ‚úÖ Good: Always update history\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"Hello\", history)\n",
    "response, history = client.chat_with_history(\"What did I just say?\", history)\n",
    "```\n",
    "\n",
    "### 2. Repeating System Prompts\n",
    "```python\n",
    "# ‚ùå Bad: Adding system prompt on every turn\n",
    "history = []\n",
    "system = \"You are a helpful assistant.\"\n",
    "response, history = client.chat_with_history(\"Hi\", history, system=system)\n",
    "response, history = client.chat_with_history(\"How are you?\", history, system=system)\n",
    "# This adds duplicate system messages!\n",
    "\n",
    "# ‚úÖ Good: System prompt only on first turn\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"Hi\", history, system=system)\n",
    "response, history = client.chat_with_history(\"How are you?\", history)\n",
    "```\n",
    "\n",
    "### 3. Using History When Not Needed\n",
    "```python\n",
    "# ‚ùå Bad: Using history for independent tasks\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"What is 2+2?\", history)\n",
    "response, history = client.chat_with_history(\"What is 5*5?\", history)\n",
    "response, history = client.chat_with_history(\"What is 10-3?\", history)\n",
    "# Unnecessary context, wastes tokens\n",
    "\n",
    "# ‚úÖ Good: Use simple chat for independent queries\n",
    "response1 = client.chat(\"What is 2+2?\")\n",
    "response2 = client.chat(\"What is 5*5?\")\n",
    "response3 = client.chat(\"What is 10-3?\")\n",
    "```\n",
    "\n",
    "### 4. Not Managing History Size\n",
    "```python\n",
    "# ‚ö†Ô∏è Warning: Long conversations consume many tokens\n",
    "history = []\n",
    "for i in range(100):  # Very long conversation\n",
    "    response, history = client.chat_with_history(f\"Message {i}\", history)\n",
    "    # Eventually hits token limits!\n",
    "\n",
    "# ‚úÖ Good: Implement sliding window for long conversations\n",
    "MAX_HISTORY = 10  # Keep last 10 messages\n",
    "if len(history) > MAX_HISTORY:\n",
    "    history = history[-MAX_HISTORY:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What You Learned\n",
    "\n",
    "‚úÖ **The Problem**: Simple `chat()` doesn't remember previous messages\n",
    "\n",
    "‚úÖ **The Solution**: Use `chat_with_history()` to maintain context\n",
    "\n",
    "‚úÖ **Message Structure**: History is a list of `ChatMessage` objects (access via `.role` and `.content`)\n",
    "\n",
    "‚úÖ **Building Conversations**: Pass history between turns, update with returned value\n",
    "\n",
    "‚úÖ **When to Use Context**: Building on previous responses vs. independent queries\n",
    "\n",
    "‚úÖ **System Prompts**: Include once on first turn, persists in history\n",
    "\n",
    "‚úÖ **Managing History**: Can inspect, modify, or truncate history manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you can maintain conversations, it's time to supercharge your LLM with **tools**!\n",
    "\n",
    "‚û°Ô∏è Continue to [04-tool-calling-basics.ipynb](./04-tool-calling-basics.ipynb) to learn how to:\n",
    "- Understand what tools are and why they're powerful\n",
    "- Use built-in tools like math_calculator and text_transformer\n",
    "- See how the SDK automatically executes tools\n",
    "- Inspect tool calls in responses\n",
    "- Combine tools with conversation history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
