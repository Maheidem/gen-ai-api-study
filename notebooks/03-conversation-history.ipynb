{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí≠ 03: Conversation History\n",
    "\n",
    "Learn how to maintain context across multiple messages to build natural, coherent conversations with your local LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- [ ] Build multi-turn conversations with context\n",
    "- [ ] Use `chat_with_history()` to maintain conversation state\n",
    "- [ ] Understand the role of message history in LLM responses\n",
    "- [ ] Recognize when context matters (and when it doesn't)\n",
    "- [ ] Manage conversation history efficiently\n",
    "- [ ] Build a complete Q&A session with memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Prerequisites\n",
    "\n",
    "- Completed notebook 02 (Basic Chat)\n",
    "- Understanding of system prompts and temperature\n",
    "- LM Studio running with a loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Estimated Time: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ The Problem: No Memory in Simple Chat\n",
    "\n",
    "Each `chat()` call is independent - the LLM doesn't remember previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Hello Alice! How can I assist you today?\n",
      "\n",
      "Response 2: I'm afraid I don't have that information, as it wasn't provided in our conversation. Could you please tell me your name?\n"
     ]
    }
   ],
   "source": [
    "from local_llm_sdk import LocalLLMClient\n",
    "\n",
    "client = LocalLLMClient(\n",
    "    base_url=\"http://169.254.83.107:1234/v1\",\n",
    "    model=\"mistralai/magistral-small-2509\"\n",
    ")\n",
    "\n",
    "# First message\n",
    "response1 = client.chat(\"My name is Alice.\")\n",
    "print(\"Response 1:\", response1)\n",
    "\n",
    "# Second message - but the LLM won't remember!\n",
    "response2 = client.chat(\"What's my name?\")\n",
    "print(\"\\nResponse 2:\", response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùå The LLM can't remember your name because each call is independent!**\n",
    "\n",
    "Each `chat()` call creates a new conversation from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ The Solution: Conversation History\n",
    "\n",
    "Use `chat_with_history()` to maintain context across multiple turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1:\n",
      "You: My name is Alice.\n",
      "LLM: Hello Alice! Nice to meet you. How can I assist you today?\n",
      "\n",
      "Turn 2:\n",
      "You: What's my name?\n",
      "LLM: Your name is Alice! How can I help you today?\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìö Conversation history now has 4 messages\n"
     ]
    }
   ],
   "source": [
    "# Start a conversation with history\n",
    "history = []\n",
    "\n",
    "# Turn 1: Introduce yourself\n",
    "response1, history = client.chat_with_history(\n",
    "    \"My name is Alice.\",\n",
    "    history\n",
    ")\n",
    "print(\"Turn 1:\")\n",
    "print(f\"You: My name is Alice.\")\n",
    "print(f\"LLM: {response1}\")\n",
    "\n",
    "# Turn 2: Ask about your name\n",
    "response2, history = client.chat_with_history(\n",
    "    \"What's my name?\",\n",
    "    history\n",
    ")\n",
    "print(\"\\nTurn 2:\")\n",
    "print(f\"You: What's my name?\")\n",
    "print(f\"LLM: {response2}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nüìö Conversation history now has {len(history)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚úÖ Now the LLM remembers!**\n",
    "\n",
    "The `chat_with_history()` method:\n",
    "1. Takes your new message\n",
    "2. Adds it to the conversation history\n",
    "3. Sends the full history to the LLM\n",
    "4. Returns both the response AND the updated history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Understanding Message History\n",
    "\n",
    "Let's peek inside the history to see what's actually stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Current conversation history:\n",
      "\n",
      "Message 1:\n",
      "  Role: user\n",
      "  Content: My name is Alice.\n",
      "\n",
      "Message 2:\n",
      "  Role: assistant\n",
      "  Content: Hello Alice! Nice to meet you. How can I assist you today?\n",
      "\n",
      "Message 3:\n",
      "  Role: user\n",
      "  Content: What's my name?\n",
      "\n",
      "Message 4:\n",
      "  Role: assistant\n",
      "  Content: Your name is Alice! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\"üìù Current conversation history:\\n\")\n",
    "for i, message in enumerate(history, 1):\n",
    "    print(f\"Message {i}:\")\n",
    "    print(f\"  Role: {message.role}\")\n",
    "    print(f\"  Content: {message.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Message Structure:**\n",
    "\n",
    "Each message is a `ChatMessage` object with two key attributes:\n",
    "- `role`: Who sent the message (\"user\", \"assistant\", or \"system\")\n",
    "- `content`: The actual text of the message\n",
    "\n",
    "Access them using dot notation: `message.role` and `message.content`\n",
    "\n",
    "The conversation alternates: user ‚Üí assistant ‚Üí user ‚Üí assistant ‚Üí ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Building a Multi-Turn Conversation\n",
    "\n",
    "Let's have a real conversation with context building over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóæ Japan Travel Planning Conversation\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üë§ You: I'm planning a trip to Japan.\n",
      "ü§ñ LLM: Great! Japan is an amazing destination with so much to offer. To give you the best advice, could you tell me a bit more about your trip? For example:\n",
      "\n",
      "1. When are you planning to visit?\n",
      "2. What cities or regions are you interested in?\n",
      "3. Do you have any specific interests (e.g., food, history, nature, shopping)?\n",
      "4. How long will your trip be?\n",
      "\n",
      "This way, I can help you plan a more tailored itinerary!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: What's the best time of year to visit?\n",
      "ü§ñ LLM: The best time to visit Japan depends on your interests:\n",
      "\n",
      "1. **Spring (March to May)**: Perfect for cherry blossom viewing, mild weather, and outdoor activities.\n",
      "2. **Autumn (September to November)**: Ideal for fall foliage, comfortable temperatures, and fewer tourists compared to spring.\n",
      "3. **Summer (June to August)**: Great if you enjoy hot weather, festivals, and outdoor events like fireworks displays.\n",
      "4. **Winter (December to February)**: Best for skiing, snow activities, and cozy onsen experiences.\n",
      "\n",
      "For many visitors, **spring and autumn** are the most pleasant times to visit due to comfortable temperatures and beautiful scenery. If you could share more about your preferences or plans, I can give a more tailored recommendation!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: I love food. What should I try?\n",
      "ü§ñ LLM: Japan is a paradise for food lovers! Here are some must-try dishes and experiences:\n",
      "\n",
      "1. **Sushi**: Try fresh sushi at Tsukiji Outer Market in Tokyo or the Dotonbori area in Osaka.\n",
      "2. **Ramen**: Each region has its specialty‚Äîtonkotsu (pork broth) in Fukuoka, miso ramen in Sapporo, and shoyu (soy sauce) ramen in Tokyo.\n",
      "3. **Sashimi**: Enjoy it at a sushi bar or a high-end restaurant for the freshest cuts.\n",
      "4. **Okonomiyaki**: Head to Osaka for this savory pancake, often cooked right in front of you.\n",
      "5. **Takoyaki**: Another Osaka specialty‚Äîcrispy outside, chewy inside with bits of octopus.\n",
      "6. **Yakitori**: Grilled chicken skewers, perfect as a snack or light meal.\n",
      "7. **Wagyu beef**: Try it at a speciality restaurant; Kobe and Matsusaka are famous for their marbled beef.\n",
      "8. **Street food**: Look for yakisoba (fried noodles), taiyaki (fish-shaped cakes filled with sweet red bean paste), and melon pan (sweet bread).\n",
      "9. **Desserts**: Matcha-flavored treats like ice cream or parfait, dorayaki (red bean pancakes), and mochi.\n",
      "10. **Regional specialties**: If you‚Äôre visiting Kyoto, try kaiseki cuisine; in Hokkaido, seek out seafood bowls like kaisendon.\n",
      "\n",
      "For an even more immersive experience:\n",
      "- Visit a local izakaya (pub) for small plates and drinks.\n",
      "- Take a food tour or cooking class to learn how to make these dishes.\n",
      "- Explore depachika‚Äîthe basement food halls of department stores, which offer a wide range of gourmet treats.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: How much would typical street food cost?\n",
      "ü§ñ LLM: Street food in Japan is generally very affordable! Here‚Äôs a rough breakdown of prices (in Japanese Yen, as of 2024):\n",
      "\n",
      "1. **Takoyaki**: ¬•300‚Äì¬•600 per plate\n",
      "2. **Yakisoba (fried noodles)**: ¬•400‚Äì¬•800\n",
      "3. **Taiyaki (fish-shaped cake)**: ¬•200‚Äì¬•500 each\n",
      "4. **Melon pan**: ¬•300‚Äì¬•600\n",
      "5. **Karaage (fried chicken)**: ¬•300‚Äì¬•700 per skewer or piece\n",
      "6. **Onigiri (rice balls)**: ¬•100‚Äì¬•300 each (convenience stores like 7-Eleven have great options!)\n",
      "7. **Dango (sweet rice dumplings)**: ¬•200‚Äì¬•500 per skewer\n",
      "8. **Okonomiyaki (Osaka-style)**: ¬•600‚Äì¬•1,500 (depending on size and toppings)\n",
      "9. **Ramune (soda)**: ¬•200‚Äì¬•400 per bottle\n",
      "\n",
      "**Budget tip**: Many stalls offer small portions, so you can try multiple things for around ¬•1,000‚Äì¬•2,000 ($7‚Äì$15 USD) per person. Convenience stores are also great for affordable snacks‚Äîthink onigiri, sandwiches, and desserts for under ¬•300 each!\n",
      "\n",
      "Would you like recommendations for specific food markets or festivals where street food is a must-try?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: Can you summarize your travel advice for me?\n",
      "ü§ñ LLM: Here's a quick summary of your Japan trip advice:\n",
      "\n",
      "**Best Time to Visit**:\n",
      "- Spring (March‚ÄìMay) for cherry blossoms or autumn (September‚ÄìNovember) for fall foliage‚Äîboth offer pleasant weather.\n",
      "\n",
      "**Must-Try Food**:\n",
      "- Street food: Takoyaki (¬•300‚Äì600), yakisoba (¬•400‚Äì800), onigiri (¬•100‚Äì300 at convenience stores).\n",
      "- Regional specialties: Osaka‚Äôs okonomiyaki, Kyoto‚Äôs kaiseki, Hokkaido seafood.\n",
      "- Budget for street food: Around ¬•1,000‚Äì2,000 ($7‚Äì15 USD) per person to sample multiple items.\n",
      "\n",
      "**General Tips**:\n",
      "- Explore depachika (department store basements) and convenience stores like 7-Eleven for delicious, affordable options.\n",
      "- If you‚Äôd like more details on specific cities or activities, let me know!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìö Final conversation: 10 messages total\n"
     ]
    }
   ],
   "source": [
    "# Start fresh\n",
    "history = []\n",
    "\n",
    "# Define a conversation\n",
    "conversation = [\n",
    "    \"I'm planning a trip to Japan.\",\n",
    "    \"What's the best time of year to visit?\",\n",
    "    \"I love food. What should I try?\",\n",
    "    \"How much would typical street food cost?\",\n",
    "    \"Can you summarize your travel advice for me?\"\n",
    "]\n",
    "\n",
    "print(\"üóæ Japan Travel Planning Conversation\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for user_message in conversation:\n",
    "    # Send message with history\n",
    "    response, history = client.chat_with_history(\n",
    "        user_message,\n",
    "        history\n",
    "    )\n",
    "    \n",
    "    # Display the exchange\n",
    "    print(f\"üë§ You: {user_message}\")\n",
    "    print(f\"ü§ñ LLM: {response}\")\n",
    "    print(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"\\nüìö Final conversation: {len(history)} messages total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Notice how the LLM:**\n",
    "- Remembers you're planning a Japan trip\n",
    "- Connects your love of food to restaurant recommendations\n",
    "- Provides cost estimates in context of food discussion\n",
    "- Summarizes the entire conversation at the end\n",
    "\n",
    "This is only possible because we maintained the conversation history!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ When Context Matters (and When It Doesn't)\n",
    "\n",
    "Context is important for some tasks but unnecessary for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WHEN CONTEXT MATTERS:\n",
      "\n",
      "You: I need a function to process data.\n",
      "LLM: Sure! Here's a generic data processing function that you can customize based on your specific needs....\n",
      "\n",
      "You: It should handle CSV files.\n",
      "LLM: Here's a CSV processing function that can handle files or strings with clean, transform, and analyze...\n",
      "\n",
      "You: And it needs to filter rows where age > 18.\n",
      "LLM: Here's the updated CSV processing function that includes filtering for rows where age is greater tha...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "‚ùå WHEN CONTEXT DOESN'T MATTER:\n",
      "\n",
      "Q: What is the capital of France?\n",
      "A: The capital of France is Paris.\n",
      "\n",
      "Q: What is 25 * 4?\n",
      "A: Let me calculate that for you.\n",
      "\n",
      "25 multiplied by 4 equals 100.\n",
      "\n",
      "Q: Translate 'hello' to Spanish.\n",
      "A: The translation of \"hello\" to Spanish is \"hola\".\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ WHEN CONTEXT MATTERS:\\n\")\n",
    "\n",
    "# Example: Refining requirements\n",
    "history = []\n",
    "\n",
    "msg1 = \"I need a function to process data.\"\n",
    "resp1, history = client.chat_with_history(msg1, history)\n",
    "print(f\"You: {msg1}\")\n",
    "print(f\"LLM: {resp1[:100]}...\\n\")\n",
    "\n",
    "msg2 = \"It should handle CSV files.\"\n",
    "resp2, history = client.chat_with_history(msg2, history)\n",
    "print(f\"You: {msg2}\")\n",
    "print(f\"LLM: {resp2[:100]}...\\n\")\n",
    "\n",
    "msg3 = \"And it needs to filter rows where age > 18.\"\n",
    "resp3, history = client.chat_with_history(msg3, history)\n",
    "print(f\"You: {msg3}\")\n",
    "print(f\"LLM: {resp3[:100]}...\\n\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "print(\"‚ùå WHEN CONTEXT DOESN'T MATTER:\\n\")\n",
    "\n",
    "# Example: Independent factual queries\n",
    "fact1 = client.chat(\"What is the capital of France?\")\n",
    "print(f\"Q: What is the capital of France?\")\n",
    "print(f\"A: {fact1}\\n\")\n",
    "\n",
    "fact2 = client.chat(\"What is 25 * 4?\")\n",
    "print(f\"Q: What is 25 * 4?\")\n",
    "print(f\"A: {fact2}\\n\")\n",
    "\n",
    "fact3 = client.chat(\"Translate 'hello' to Spanish.\")\n",
    "print(f\"Q: Translate 'hello' to Spanish.\")\n",
    "print(f\"A: {fact3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Use context when:**\n",
    "- Building on previous responses\n",
    "- Refining requirements or ideas\n",
    "- Having natural conversations\n",
    "- Working on a single topic over multiple turns\n",
    "- When \"it\" or \"that\" refers to earlier messages\n",
    "\n",
    "**üí° Skip context when:**\n",
    "- Asking independent factual questions\n",
    "- Performing simple calculations\n",
    "- Doing batch operations on unrelated items\n",
    "- Testing different prompts on the same task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Managing History: System Prompts\n",
    "\n",
    "You can include a system prompt when starting a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1:\n",
      "A list comprehension is a syntactical construct available in programming languages like Python that provides a concise way to create lists by applying an expression to each item in an existing iterable (such as a list or tuple), often with an optional condition to filter items. The basic syntax in Python is:\n",
      "\n",
      "```python\n",
      "[expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "For example, to generate a list of squares of even numbers from 1 to 5, you could write:\n",
      "```python\n",
      "[x**2 for x in range(1,6) if x % 2 == 0]\n",
      "```\n",
      "This would produce the output `[4, 16]`.\n",
      "\n",
      "List comprehensions can also include nested loops and more complex expressions, making them a powerful tool for data transformation. For instance, creating pairs of numbers from two ranges can be done with:\n",
      "```python\n",
      "[(x, y) for x in range(3) for y in range(2)]\n",
      "```\n",
      "This results in `[(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]`. While commonly associated with Python, similar constructs exist in other languages under different names or variations.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Turn 2:\n",
      "Here's a more complex example of a list comprehension that involves multiple conditions and nested loops:\n",
      "\n",
      "```python\n",
      "fruits = ['apple', 'banana', 'cherry', 'date', 'elderberry']\n",
      "colors = ['red', 'green', 'blue', 'black', 'white']\n",
      "\n",
      "# Create pairs where the fruit starts with a vowel (a, e) and color is not black\n",
      "valid_pairs = [\n",
      "    (fruit, color)\n",
      "    for fruit in fruits\n",
      "    if fruit[0].lower() in {'a', 'e'}\n",
      "    for color in colors\n",
      "    if color != 'black'\n",
      "]\n",
      "\n",
      "print(valid_pairs)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "```\n",
      "[('apple', 'red'), ('apple', 'green'), ('apple', 'blue'), ('apple', 'white'),\n",
      " ('elderberry', 'red'), ('elderberry', 'green'), ('elderberry', 'blue'), ('elderberry', 'white')]\n",
      "```\n",
      "\n",
      "In this example, we:\n",
      "1. Iterate over each fruit in the `fruits` list\n",
      "2. Filter to keep only fruits that start with a vowel (a or e)\n",
      "3. For each of those fruits, iterate over all colors\n",
      "4. Further filter out any pairs where the color is 'black'\n",
      "\n",
      "This demonstrates how list comprehensions can be used to express complex transformations and filtering in a concise way. The result is a list of tuples containing only valid fruit-color combinations that meet our criteria.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üìù History structure:\n",
      "  - user: What is a list comprehension?...\n",
      "  - assistant: A list comprehension is a syntactical construct av...\n",
      "  - user: Show me a more complex example....\n",
      "  - assistant: Here's a more complex example of a list comprehens...\n"
     ]
    }
   ],
   "source": [
    "# Start with a system prompt\n",
    "history = []\n",
    "system_prompt = \"You are a helpful Python tutor who explains concepts simply with code examples.\"\n",
    "\n",
    "# First message - include system prompt\n",
    "response1, history = client.chat_with_history(\n",
    "    \"What is a list comprehension?\",\n",
    "    history,\n",
    "    system=system_prompt\n",
    ")\n",
    "print(\"Turn 1:\")\n",
    "print(response1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Subsequent messages - no need to repeat system prompt!\n",
    "response2, history = client.chat_with_history(\n",
    "    \"Show me a more complex example.\",\n",
    "    history\n",
    ")\n",
    "print(\"Turn 2:\")\n",
    "print(response2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "print(\"üìù History structure:\")\n",
    "for msg in history:\n",
    "    print(f\"  - {msg.role}: {msg.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Important:** Only include `system` parameter on the FIRST call. The system message becomes part of the history and persists automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Advanced: Inspecting and Modifying History\n",
    "\n",
    "You can manually inspect or modify the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original response: Here's what I remember about your favorites from our conversation so far:\n",
      "- Favorite color: blue\n",
      "- Favorite food: pizza\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Response with modified history: Here are your favorites that we've discussed so far:\n",
      "\n",
      "- Favorite color: Blue\n",
      "- Favorite food: Pizza\n",
      "\n",
      "If there's anything else you'd like me to remember or if you'd like to add more favorites, let me know!\n",
      "\n",
      "üí° Now it only remembers your color preference!\n"
     ]
    }
   ],
   "source": [
    "# Start a conversation\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"My favorite color is blue.\", history)\n",
    "response, history = client.chat_with_history(\"My favorite food is pizza.\", history)\n",
    "response, history = client.chat_with_history(\"What are my favorites?\", history)\n",
    "\n",
    "print(\"Original response:\", response)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Manually remove the food preference from history\n",
    "# (Keep only system, first user msg, first assistant msg, and last question)\n",
    "modified_history = [history[0], history[1], history[-1]]\n",
    "\n",
    "# Ask again with modified history\n",
    "response2, _ = client.chat_with_history(\n",
    "    \"What are my favorites?\",\n",
    "    modified_history\n",
    ")\n",
    "\n",
    "print(\"Response with modified history:\", response2)\n",
    "print(\"\\nüí° Now it only remembers your color preference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è Advanced technique:** Manually editing history is useful for:\n",
    "- Removing sensitive information\n",
    "- Keeping only relevant context (token optimization)\n",
    "- Correcting mistakes in the conversation\n",
    "- Implementing sliding window context (keep last N messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise: Build a Quiz Game\n",
    "\n",
    "**Challenge:** Create a Q&A quiz session where:\n",
    "1. The LLM asks you 3 trivia questions (one at a time)\n",
    "2. You provide answers\n",
    "3. The LLM evaluates each answer\n",
    "4. At the end, the LLM summarizes your score\n",
    "\n",
    "Requirements:\n",
    "- Use `chat_with_history()` to maintain context\n",
    "- Use a system prompt to make the LLM a quiz host\n",
    "- Must have at least 5+ turns (intro, Q1, A1, Q2, A2, Q3, A3, summary)\n",
    "\n",
    "Try it yourself first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Solution: Quiz game with conversation history\n",
    "\n",
    "history = []\n",
    "system_prompt = \"\"\"\n",
    "You are a friendly quiz show host. Ask the user 3 trivia questions, one at a time.\n",
    "After each answer, tell them if they're correct and give the right answer if they're wrong.\n",
    "After all 3 questions, summarize their score.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéÆ TRIVIA QUIZ GAME\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start the quiz\n",
    "response, history = client.chat_with_history(\n",
    "    \"Let's start the quiz!\",\n",
    "    history,\n",
    "    system=system_prompt\n",
    ")\n",
    "print(f\"üé§ Host: {response}\\n\")\n",
    "\n",
    "# User answers (you can modify these)\n",
    "answers = [\n",
    "    \"Paris\",           # If question is about France's capital\n",
    "    \"I don't know\",    # Skip a question\n",
    "    \"42\"               # Random guess\n",
    "]\n",
    "\n",
    "for i, answer in enumerate(answers, 1):\n",
    "    # Provide answer\n",
    "    print(f\"üë§ You: {answer}\")\n",
    "    response, history = client.chat_with_history(answer, history)\n",
    "    print(f\"üé§ Host: {response}\\n\")\n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "\n",
    "# Get final summary\n",
    "if \"score\" not in response.lower() and \"how did\" not in response.lower():\n",
    "    response, history = client.chat_with_history(\n",
    "        \"Can you tell me my final score?\",\n",
    "        history\n",
    "    )\n",
    "    print(f\"üë§ You: Can you tell me my final score?\")\n",
    "    print(f\"üé§ Host: {response}\")\n",
    "\n",
    "print(f\"\\n\\nüìä Total conversation turns: {len(history)}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ TRIVIA QUIZ GAME\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üé§ Host: Great! Let's begin the quiz. We'll start with some general knowledge questions. Here's your first question:\n",
      "\n",
      "What is the capital of France?\n",
      "\n",
      "A) London\n",
      "B) Paris\n",
      "C) Berlin\n",
      "D) Madrid\n",
      "\n",
      "Please reply with the letter corresponding to your answer. Good luck!\n",
      "\n",
      "üë§ You: Paris\n",
      "üé§ Host: Correct! The capital of France is Paris.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "Who wrote the play \"Romeo and Juliet\"?\n",
      "\n",
      "A) Charles Dickens\n",
      "B) William Shakespeare\n",
      "C) Jane Austen\n",
      "D) Mark Twain\n",
      "\n",
      "Please reply with the letter corresponding to your answer.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: I don't know\n",
      "üé§ Host: The correct answer is B) William Shakespeare.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "What is the largest planet in our solar system?\n",
      "\n",
      "A) Earth\n",
      "B) Mars\n",
      "C) Jupiter\n",
      "D) Venus\n",
      "\n",
      "Please reply with the letter corresponding to your answer.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: 42\n",
      "üé§ Host: It looks like you provided a numerical answer, but the options are letters (A, B, C, D). However, I recognize that 42 is a famous answer from \"The Hitchhiker's Guide to the Galaxy\"! For this question, let me remind you of the options:\n",
      "\n",
      "What is the largest planet in our solar system?\n",
      "\n",
      "A) Earth\n",
      "B) Mars\n",
      "C) Jupiter\n",
      "D) Venus\n",
      "\n",
      "If you meant option C (Jupiter), that would be correct! Let me know if that was your intention or if you'd like to answer again.\n",
      "\n",
      "Alternatively, here's the next question:\n",
      "\n",
      "What is the chemical symbol for gold?\n",
      "\n",
      "A) Go\n",
      "B) Au\n",
      "C) Ag\n",
      "D) Fe\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üë§ You: Can you tell me my final score?\n",
      "üé§ Host: It seems you've answered two questions correctly so far (the capital of France and the largest planet in our solar system). Since you haven't answered the chemical symbol for gold yet, your current score is 2 out of 3 attempted questions.\n",
      "\n",
      "Would you like to answer that last question now, or should we consider this as your final score?\n",
      "\n",
      "If this is your final score:\n",
      "- Questions answered: 3 (with one hint from me)\n",
      "- Correct answers: 2\n",
      "So your score would be 2/3. Would you like to confirm if this is your final score?\n",
      "\n",
      "\n",
      "üìä Total conversation turns: 10\n"
     ]
    }
   ],
   "source": [
    "# Solution cell (run this to see the answer)\n",
    "history = []\n",
    "system_prompt = \"\"\"\n",
    "You are a friendly quiz show host. Ask the user 3 trivia questions, one at a time.\n",
    "After each answer, tell them if they're correct and give the right answer if they're wrong.\n",
    "After all 3 questions, summarize their score.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéÆ TRIVIA QUIZ GAME\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Start the quiz\n",
    "response, history = client.chat_with_history(\n",
    "    \"Let's start the quiz!\",\n",
    "    history,\n",
    "    system=system_prompt\n",
    ")\n",
    "print(f\"üé§ Host: {response}\\n\")\n",
    "\n",
    "# User answers (you can modify these)\n",
    "answers = [\n",
    "    \"Paris\",\n",
    "    \"I don't know\",\n",
    "    \"42\"\n",
    "]\n",
    "\n",
    "for i, answer in enumerate(answers, 1):\n",
    "    print(f\"üë§ You: {answer}\")\n",
    "    response, history = client.chat_with_history(answer, history)\n",
    "    print(f\"üé§ Host: {response}\\n\")\n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "\n",
    "# Get final summary\n",
    "if \"score\" not in response.lower() and \"how did\" not in response.lower():\n",
    "    response, history = client.chat_with_history(\n",
    "        \"Can you tell me my final score?\",\n",
    "        history\n",
    "    )\n",
    "    print(f\"üë§ You: Can you tell me my final score?\")\n",
    "    print(f\"üé§ Host: {response}\")\n",
    "\n",
    "print(f\"\\n\\nüìä Total conversation turns: {len(history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Common Pitfalls\n",
    "\n",
    "### 1. Forgetting to Update History\n",
    "```python\n",
    "# ‚ùå Bad: Not using the returned history\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"Hello\", history)\n",
    "response, _ = client.chat_with_history(\"What did I just say?\", history)  # Wrong!\n",
    "# The second message won't remember \"Hello\"\n",
    "\n",
    "# ‚úÖ Good: Always update history\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"Hello\", history)\n",
    "response, history = client.chat_with_history(\"What did I just say?\", history)\n",
    "```\n",
    "\n",
    "### 2. Repeating System Prompts\n",
    "```python\n",
    "# ‚ùå Bad: Adding system prompt on every turn\n",
    "history = []\n",
    "system = \"You are a helpful assistant.\"\n",
    "response, history = client.chat_with_history(\"Hi\", history, system=system)\n",
    "response, history = client.chat_with_history(\"How are you?\", history, system=system)\n",
    "# This adds duplicate system messages!\n",
    "\n",
    "# ‚úÖ Good: System prompt only on first turn\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"Hi\", history, system=system)\n",
    "response, history = client.chat_with_history(\"How are you?\", history)\n",
    "```\n",
    "\n",
    "### 3. Using History When Not Needed\n",
    "```python\n",
    "# ‚ùå Bad: Using history for independent tasks\n",
    "history = []\n",
    "response, history = client.chat_with_history(\"What is 2+2?\", history)\n",
    "response, history = client.chat_with_history(\"What is 5*5?\", history)\n",
    "response, history = client.chat_with_history(\"What is 10-3?\", history)\n",
    "# Unnecessary context, wastes tokens\n",
    "\n",
    "# ‚úÖ Good: Use simple chat for independent queries\n",
    "response1 = client.chat(\"What is 2+2?\")\n",
    "response2 = client.chat(\"What is 5*5?\")\n",
    "response3 = client.chat(\"What is 10-3?\")\n",
    "```\n",
    "\n",
    "### 4. Not Managing History Size\n",
    "```python\n",
    "# ‚ö†Ô∏è Warning: Long conversations consume many tokens\n",
    "history = []\n",
    "for i in range(100):  # Very long conversation\n",
    "    response, history = client.chat_with_history(f\"Message {i}\", history)\n",
    "    # Eventually hits token limits!\n",
    "\n",
    "# ‚úÖ Good: Implement sliding window for long conversations\n",
    "MAX_HISTORY = 10  # Keep last 10 messages\n",
    "if len(history) > MAX_HISTORY:\n",
    "    history = history[-MAX_HISTORY:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What You Learned\n",
    "\n",
    "‚úÖ **The Problem**: Simple `chat()` doesn't remember previous messages\n",
    "\n",
    "‚úÖ **The Solution**: Use `chat_with_history()` to maintain context\n",
    "\n",
    "‚úÖ **Message Structure**: History is a list of `ChatMessage` objects (access via `.role` and `.content`)\n",
    "\n",
    "‚úÖ **Building Conversations**: Pass history between turns, update with returned value\n",
    "\n",
    "‚úÖ **When to Use Context**: Building on previous responses vs. independent queries\n",
    "\n",
    "‚úÖ **System Prompts**: Include once on first turn, persists in history\n",
    "\n",
    "‚úÖ **Managing History**: Can inspect, modify, or truncate history manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you can maintain conversations, it's time to supercharge your LLM with **tools**!\n",
    "\n",
    "‚û°Ô∏è Continue to [04-tool-calling-basics.ipynb](./04-tool-calling-basics.ipynb) to learn how to:\n",
    "- Understand what tools are and why they're powerful\n",
    "- Use built-in tools like math_calculator and text_transformer\n",
    "- See how the SDK automatically executes tools\n",
    "- Inspect tool calls in responses\n",
    "- Combine tools with conversation history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
