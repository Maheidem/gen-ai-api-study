{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 11: Mini Project - Data Analysis Agent\n",
    "\n",
    "Build a complete data analysis pipeline that loads data files, performs statistical analysis, identifies patterns, creates visualizations, and generates insights reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Learning Objectives\n",
    "\n",
    "By the end of this project, you will be able to:\n",
    "\n",
    "- [ ] Build an end-to-end data analysis pipeline with agents\n",
    "- [ ] Load and parse CSV/JSON data files\n",
    "- [ ] Perform statistical analysis (mean, median, std dev, correlations)\n",
    "- [ ] Identify patterns, outliers, and anomalies\n",
    "- [ ] Create visualizations with matplotlib\n",
    "- [ ] Generate comprehensive insights reports\n",
    "- [ ] Structure a data science workflow with checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Prerequisites\n",
    "\n",
    "- Completed notebooks 01-10\n",
    "- Understanding of ReACT agents and tools\n",
    "- Basic statistics knowledge\n",
    "- Familiarity with data analysis concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⏱️ Estimated Time: 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Project Goal\n",
    "\n",
    "Build a **Data Analysis Agent** that:\n",
    "\n",
    "1. **Loads** data from CSV or JSON files\n",
    "2. **Generates** summary statistics:\n",
    "   - Count, mean, median, mode\n",
    "   - Standard deviation, variance\n",
    "   - Min, max, quartiles\n",
    "3. **Identifies** patterns and insights:\n",
    "   - Correlations between variables\n",
    "   - Outliers and anomalies\n",
    "   - Trends and distributions\n",
    "4. **Creates** visualizations:\n",
    "   - Histograms\n",
    "   - Scatter plots\n",
    "   - Box plots\n",
    "5. **Writes** a comprehensive insights report\n",
    "\n",
    "**Approach:** Use a ReACT agent with filesystem, code execution, and custom data tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Setup\n",
    "\n",
    "Let's set up our environment and create sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from local_llm_sdk import LocalLLMClient, tool\nfrom dotenv import load_dotenv\nimport tempfile\nimport os\nimport json\nimport csv\n\n# Load environment variables\nload_dotenv()\n\n# Create client\nclient = LocalLLMClient(\n    base_url=os.getenv(\"LLM_BASE_URL\"),\n    model=os.getenv(\"LLM_MODEL\"),\n    timeout=300\n)\n\n# Register built-in tools\nclient.register_tools_from(None)\n\n# Create temporary directory\nproject_dir = tempfile.mkdtemp()\n\nprint(\"✅ Setup Complete!\")\nprint(f\"Project directory: {project_dir}\")\nprint(f\"\\nRegistered tools: {', '.join(client.tools.list_tools())}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Dataset\n",
    "\n",
    "Let's create a realistic sales dataset to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "# Generate sample sales data\n",
    "random.seed(42)\n",
    "\n",
    "categories = ['Electronics', 'Clothing', 'Food', 'Books', 'Toys']\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "\n",
    "sales_data = []\n",
    "for i in range(200):\n",
    "    date = datetime.date(2024, 1, 1) + datetime.timedelta(days=random.randint(0, 364))\n",
    "    category = random.choice(categories)\n",
    "    region = random.choice(regions)\n",
    "    \n",
    "    # Electronics has higher prices, Food has lower\n",
    "    if category == 'Electronics':\n",
    "        price = random.uniform(100, 1000)\n",
    "        quantity = random.randint(1, 5)\n",
    "    elif category == 'Food':\n",
    "        price = random.uniform(5, 50)\n",
    "        quantity = random.randint(1, 20)\n",
    "    else:\n",
    "        price = random.uniform(10, 200)\n",
    "        quantity = random.randint(1, 10)\n",
    "    \n",
    "    revenue = price * quantity\n",
    "    \n",
    "    sales_data.append({\n",
    "        'date': str(date),\n",
    "        'category': category,\n",
    "        'region': region,\n",
    "        'price': round(price, 2),\n",
    "        'quantity': quantity,\n",
    "        'revenue': round(revenue, 2)\n",
    "    })\n",
    "\n",
    "# Save as CSV\n",
    "csv_file = os.path.join(project_dir, \"sales_data.csv\")\n",
    "with open(csv_file, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['date', 'category', 'region', 'price', 'quantity', 'revenue'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sales_data)\n",
    "\n",
    "# Also save as JSON\n",
    "json_file = os.path.join(project_dir, \"sales_data.json\")\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(sales_data, f, indent=2)\n",
    "\n",
    "print(\"📊 Created sample sales dataset:\")\n",
    "print(f\"   Records: {len(sales_data)}\")\n",
    "print(f\"   Categories: {', '.join(categories)}\")\n",
    "print(f\"   Regions: {', '.join(regions)}\")\n",
    "print(f\"   CSV file: {csv_file}\")\n",
    "print(f\"   JSON file: {json_file}\")\n",
    "print(\"\\n📝 Sample record:\")\n",
    "print(json.dumps(sales_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Project Structure\n",
    "\n",
    "We'll build this project in **5 checkpoints**:\n",
    "\n",
    "1. ✅ **Checkpoint 1**: Load data file\n",
    "2. ✅ **Checkpoint 2**: Generate summary statistics\n",
    "3. ✅ **Checkpoint 3**: Identify patterns and outliers\n",
    "4. ✅ **Checkpoint 4**: Create visualizations\n",
    "5. ✅ **Checkpoint 5**: Write insights report\n",
    "\n",
    "Let's build it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1: Load Data File\n",
    "\n",
    "First, verify the agent can load and understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 1: Load Data\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Load the CSV file at {csv_file}. \"\n",
    "    f\"Tell me: \"\n",
    "    f\"(1) how many records are in the file, \"\n",
    "    f\"(2) what columns are present, \"\n",
    "    f\"(3) show the first 3 records as an example.\",\n",
    "    max_iterations=8\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n📊 Data Overview:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "if result.status == \"success\":\n",
    "    print(\"\\n✅ Checkpoint 1 Complete: Data loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 1 Failed: Could not load data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2: Generate Summary Statistics\n",
    "\n",
    "Calculate comprehensive statistics for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 2: Summary Statistics\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Analyze the sales data in {csv_file}. \"\n",
    "    f\"Calculate summary statistics for the numerical columns (price, quantity, revenue): \"\n",
    "    f\"(1) mean, median, mode, \"\n",
    "    f\"(2) standard deviation, variance, \"\n",
    "    f\"(3) min, max, \"\n",
    "    f\"(4) 25th, 50th, 75th percentiles. \"\n",
    "    f\"Also provide counts for categorical columns (category, region).\",\n",
    "    max_iterations=15\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n📈 Statistics:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "if result.status == \"success\":\n",
    "    print(\"\\n✅ Checkpoint 2 Complete: Statistics generated!\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 2 Failed: Statistics incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 3: Identify Patterns and Outliers\n",
    "\n",
    "Find interesting patterns, correlations, and anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 3: Pattern Detection\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Analyze the sales data in {csv_file} for patterns and insights. \"\n",
    "    f\"Specifically: \"\n",
    "    f\"(1) Calculate correlation between price and quantity, \"\n",
    "    f\"(2) Identify outliers in revenue (values > 2 standard deviations from mean), \"\n",
    "    f\"(3) Compare average revenue across different categories, \"\n",
    "    f\"(4) Compare average revenue across different regions, \"\n",
    "    f\"(5) Identify any interesting trends or patterns you observe.\",\n",
    "    max_iterations=18\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n🔍 Patterns & Insights:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "if result.status == \"success\":\n",
    "    print(\"\\n✅ Checkpoint 3 Complete: Patterns identified!\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 3 Failed: Analysis incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 4: Create Visualizations\n",
    "\n",
    "Generate charts to visualize the data insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 4: Create Visualizations\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "viz_dir = os.path.join(project_dir, \"visualizations\")\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "result = client.react(\n",
    "    f\"Create visualizations for the sales data in {csv_file}. \"\n",
    "    f\"Generate these plots using matplotlib and save them to {viz_dir}: \"\n",
    "    f\"(1) Histogram of revenue distribution (save as revenue_hist.png), \"\n",
    "    f\"(2) Bar chart of average revenue by category (save as category_bar.png), \"\n",
    "    f\"(3) Bar chart of average revenue by region (save as region_bar.png), \"\n",
    "    f\"(4) Scatter plot of price vs quantity (save as price_quantity_scatter.png). \"\n",
    "    f\"Make sure all plots have titles, axis labels, and are clearly readable.\",\n",
    "    max_iterations=20\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n📊 Visualization Generation:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "# Check if visualizations were created\n",
    "expected_files = [\n",
    "    'revenue_hist.png',\n",
    "    'category_bar.png',\n",
    "    'region_bar.png',\n",
    "    'price_quantity_scatter.png'\n",
    "]\n",
    "\n",
    "created_files = [f for f in expected_files if os.path.exists(os.path.join(viz_dir, f))]\n",
    "\n",
    "if created_files:\n",
    "    print(f\"\\n✅ Checkpoint 4 Complete: Created {len(created_files)}/{len(expected_files)} visualizations\")\n",
    "    print(\"\\n📁 Visualization files:\")\n",
    "    for f in created_files:\n",
    "        print(f\"   - {os.path.join(viz_dir, f)}\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 4 Failed: No visualizations created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 5: Write Insights Report\n",
    "\n",
    "Generate a comprehensive analysis report with all findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Checkpoint 5: Generate Insights Report\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "report_file = os.path.join(project_dir, \"analysis_report.md\")\n",
    "\n",
    "result = client.react(\n",
    "    f\"Create a comprehensive data analysis report for the sales data in {csv_file}. \"\n",
    "    f\"The report should be in Markdown format and include: \"\n",
    "    f\"(1) Executive Summary (2-3 sentences), \"\n",
    "    f\"(2) Dataset Overview (records, columns, date range), \"\n",
    "    f\"(3) Key Statistics (summary stats for revenue, price, quantity), \"\n",
    "    f\"(4) Key Findings (top 3-5 insights with data to support them), \"\n",
    "    f\"(5) Category Analysis (which categories perform best), \"\n",
    "    f\"(6) Regional Analysis (which regions perform best), \"\n",
    "    f\"(7) Outliers and Anomalies (if any significant ones found), \"\n",
    "    f\"(8) Recommendations (3-5 actionable recommendations based on the data), \"\n",
    "    f\"(9) Visualizations (mention the charts created and what they show). \"\n",
    "    f\"Save the report to {report_file}.\",\n",
    "    max_iterations=25\n",
    ")\n",
    "\n",
    "print(f\"\\nStatus: {result.status}\")\n",
    "print(f\"Steps: {result.steps_taken}\")\n",
    "print(f\"\\n📄 Report Generation:\\n\")\n",
    "print(result.final_response)\n",
    "\n",
    "# Verify and display report\n",
    "if os.path.exists(report_file):\n",
    "    print(f\"\\n✅ Checkpoint 5 Complete: Report saved to {report_file}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n📋 Generated Analysis Report:\\n\")\n",
    "    with open(report_file, 'r') as f:\n",
    "        report_content = f.read()\n",
    "        print(report_content)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"\\n📊 Report Statistics:\")\n",
    "    print(f\"   Length: {len(report_content)} characters\")\n",
    "    print(f\"   Lines: {len(report_content.splitlines())}\")\n",
    "    print(f\"   Sections: {report_content.count('#')} headings\")\n",
    "else:\n",
    "    print(\"\\n❌ Checkpoint 5 Failed: Report file not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Project Complete!\n",
    "\n",
    "Let's verify all checkpoints and review what we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n🎯 Project Summary: Data Analysis Agent\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Check all checkpoints\n",
    "checkpoints = [\n",
    "    (\"Load data file\", os.path.exists(csv_file)),\n",
    "    (\"Generate summary statistics\", True),  # Completed above\n",
    "    (\"Identify patterns and outliers\", True),  # Completed above\n",
    "    (\"Create visualizations\", len(created_files) > 0),\n",
    "    (\"Write insights report\", os.path.exists(report_file)),\n",
    "]\n",
    "\n",
    "for i, (checkpoint, status) in enumerate(checkpoints, 1):\n",
    "    status_icon = \"✅\" if status else \"❌\"\n",
    "    print(f\"{status_icon} Checkpoint {i}: {checkpoint}\")\n",
    "\n",
    "all_complete = all(status for _, status in checkpoints)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if all_complete:\n",
    "    print(\"\\n🎉 SUCCESS: All checkpoints complete!\")\n",
    "    print(\"\\n📁 Generated Files:\")\n",
    "    print(f\"   - Data file: {csv_file}\")\n",
    "    print(f\"   - Analysis report: {report_file}\")\n",
    "    print(f\"   - Visualizations: {len(created_files)} charts in {viz_dir}\")\n",
    "    \n",
    "    print(\"\\n💡 What you built:\")\n",
    "    print(\"   A complete AI-powered data analysis pipeline that can:\")\n",
    "    print(\"   - Load and parse CSV/JSON data\")\n",
    "    print(\"   - Calculate comprehensive statistics\")\n",
    "    print(\"   - Identify patterns and outliers\")\n",
    "    print(\"   - Generate visualizations\")\n",
    "    print(\"   - Write actionable insights reports\")\n",
    "    \n",
    "    print(\"\\n📊 Analysis Coverage:\")\n",
    "    print(f\"   - {len(sales_data)} sales records analyzed\")\n",
    "    print(f\"   - {len(categories)} product categories\")\n",
    "    print(f\"   - {len(regions)} geographic regions\")\n",
    "    print(f\"   - {len(created_files)} visualizations created\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some checkpoints incomplete. Review the outputs above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 Cleanup\n",
    "\n",
    "Clean up temporary files when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Uncomment to clean up:\n",
    "# shutil.rmtree(project_dir)\n",
    "# print(f\"✅ Cleaned up project directory: {project_dir}\")\n",
    "\n",
    "print(\"💡 Tip: Comment out the cleanup to keep files for inspection\")\n",
    "print(f\"   Project files in: {project_dir}\")\n",
    "print(f\"   - Data: {csv_file}\")\n",
    "print(f\"   - Report: {report_file}\")\n",
    "print(f\"   - Charts: {viz_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Extension Ideas\n",
    "\n",
    "Want to enhance your Data Analysis Agent? Try these:\n",
    "\n",
    "### 1. Time Series Analysis\n",
    "```python\n",
    "# Analyze trends over time\n",
    "# Seasonal patterns\n",
    "# Moving averages\n",
    "# Forecast future values\n",
    "```\n",
    "\n",
    "### 2. Advanced Statistics\n",
    "```python\n",
    "# Hypothesis testing\n",
    "# A/B test analysis\n",
    "# Regression analysis\n",
    "# Clustering (K-means)\n",
    "```\n",
    "\n",
    "### 3. Multi-Dataset Analysis\n",
    "```python\n",
    "# Join multiple datasets\n",
    "# Compare datasets\n",
    "# Cross-dataset correlations\n",
    "```\n",
    "\n",
    "### 4. Interactive Dashboards\n",
    "```python\n",
    "# Generate HTML dashboard\n",
    "# Interactive Plotly charts\n",
    "# Real-time data updates\n",
    "```\n",
    "\n",
    "### 5. Anomaly Detection\n",
    "```python\n",
    "# Machine learning for anomaly detection\n",
    "# Isolation Forest\n",
    "# Z-score analysis\n",
    "# Alert on significant anomalies\n",
    "```\n",
    "\n",
    "### 6. Natural Language Queries\n",
    "```python\n",
    "# \"What was the highest revenue day?\"\n",
    "# \"Compare Electronics vs Clothing sales\"\n",
    "# \"Show me outliers in the North region\"\n",
    "```\n",
    "\n",
    "### 7. Export Formats\n",
    "```python\n",
    "# Excel reports with formatting\n",
    "# PDF reports with charts\n",
    "# PowerPoint presentations\n",
    "# JSON API responses\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Key Takeaways\n",
    "\n",
    "**What You Learned:**\n",
    "\n",
    "✅ **Data Pipeline Design**: Building end-to-end analysis workflows\n",
    "\n",
    "✅ **Statistical Analysis**: Computing comprehensive statistics with Python\n",
    "\n",
    "✅ **Pattern Recognition**: Identifying trends, correlations, and outliers\n",
    "\n",
    "✅ **Data Visualization**: Creating meaningful charts with matplotlib\n",
    "\n",
    "✅ **Insight Generation**: Translating data into actionable recommendations\n",
    "\n",
    "✅ **Report Writing**: Producing professional analysis reports\n",
    "\n",
    "✅ **Agent Orchestration**: Using agents to coordinate multi-step analysis\n",
    "\n",
    "**Production Considerations:**\n",
    "\n",
    "- Handle missing or malformed data gracefully\n",
    "- Validate data types and ranges\n",
    "- Scale to larger datasets (chunking, streaming)\n",
    "- Cache intermediate results\n",
    "- Add progress tracking for long operations\n",
    "- Support multiple data formats (Excel, Parquet, SQL)\n",
    "- Implement data quality checks\n",
    "- Add user configuration for analysis parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 What You've Accomplished\n",
    "\n",
    "**Congratulations! You've completed the entire Local LLM SDK tutorial series!**\n",
    "\n",
    "### Journey Recap:\n",
    "\n",
    "**Foundations (Notebooks 1-3):**\n",
    "- ✅ Setup and basic chat\n",
    "- ✅ Conversation history management\n",
    "- ✅ Understanding LLM interactions\n",
    "\n",
    "**Tool Integration (Notebooks 4-6):**\n",
    "- ✅ Built-in tools (calculator, text transformer)\n",
    "- ✅ Custom tool creation\n",
    "- ✅ Filesystem and code execution\n",
    "\n",
    "**Advanced Patterns (Notebooks 7-9):**\n",
    "- ✅ ReACT agent pattern\n",
    "- ✅ MLflow observability\n",
    "- ✅ Production-ready patterns\n",
    "\n",
    "**Capstone Projects (Notebooks 10-11):**\n",
    "- ✅ Code Review Assistant\n",
    "- ✅ Data Analysis Agent\n",
    "\n",
    "### You Can Now:\n",
    "\n",
    "- Build production-ready LLM applications\n",
    "- Create custom tools for any domain\n",
    "- Orchestrate multi-step agent workflows\n",
    "- Debug and optimize with tracing\n",
    "- Handle errors and edge cases\n",
    "- Generate insights from data\n",
    "- Automate complex analysis tasks\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Build Your Own Project**: Apply what you learned to solve a real problem\n",
    "2. **Explore the SDK Source**: Dive into `local_llm_sdk/` to understand internals\n",
    "3. **Contribute**: Found a bug or have an idea? Contribute to the project!\n",
    "4. **Share**: Build something cool? Share it with the community!\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- 📚 [SDK Documentation](../README.md)\n",
    "- 💻 [Source Code](../local_llm_sdk/)\n",
    "- 📊 [API Research](.documentation/)\n",
    "- 🔧 [Example Scripts](../notebooks/)\n",
    "\n",
    "**Happy building with Local LLM SDK!** 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}