{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí¨ 02: Basic Chat Interactions\n",
    "\n",
    "Learn how to interact with local LLMs using simple chat requests, control behavior with system prompts, and adjust creativity with temperature settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- [ ] Send simple chat messages to a local LLM\n",
    "- [ ] Use system prompts to control the AI's personality and behavior\n",
    "- [ ] Adjust temperature to control response randomness\n",
    "- [ ] Choose between full and simple response formats\n",
    "- [ ] Create a chatbot with a specific personality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Prerequisites\n",
    "\n",
    "- Completed notebook 01 (Hello World)\n",
    "- LM Studio running with a loaded model\n",
    "- `local_llm_sdk` package installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Estimated Time: 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Simple String Chat\n",
    "\n",
    "The easiest way to chat with an LLM is using a simple string. The SDK handles all the complexity behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_llm_sdk import LocalLLMClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create a client\n",
    "client = LocalLLMClient(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")\n",
    "\n",
    "# Simple chat - just pass a string!\n",
    "response = client.chat(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° What just happened?**\n",
    "\n",
    "The `chat()` method:\n",
    "1. Wrapped your string in the proper message format\n",
    "2. Sent it to LM Studio\n",
    "3. Extracted just the text content from the response\n",
    "4. Returned a clean string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ System Prompts: Controlling Personality\n",
    "\n",
    "System prompts set the AI's behavior, personality, and constraints. They're like giving the AI instructions before the conversation starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default behavior:\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability. Here are its key aspects:\n",
      "\n",
      "## Core Features\n",
      "- **Easy to learn**: Clean, readable syntax that resembles English\n",
      "- **Interpreted**: No compilation needed; code runs directly\n",
      "- **Dynamically typed**: Variables don't need explicit type declarations\n",
      "- **Multi-paradigm**: Supports procedural, object-oriented, and functional programming\n",
      "\n",
      "## Common Use Cases\n",
      "- **Web development** (Django, Flask frameworks)\n",
      "- **Data science and analysis** (pandas, NumPy, matplotlib)\n",
      "- **Artificial intelligence/Machine Learning** (TensorFlow, PyTorch, scikit-learn)\n",
      "- **Automation and scripting**\n",
      "- **Desktop applications** (with libraries like Tkinter)\n",
      "- **Scientific computing**\n",
      "\n",
      "## Key Characteristics\n",
      "- **Large standard library**: Built-in modules for many tasks\n",
      "- **Strong community**: Extensive third-party packages via PyPI\n",
      "- **Cross-platform**: Runs on Windows, macOS, Linux\n",
      "- **Memory management**: Automatic garbage collection\n",
      "\n",
      "## Basic Example\n",
      "```python\n",
      "# Simple \"Hello, World!\" program\n",
      "print(\"Hello, World!\")\n",
      "\n",
      "# Basic function\n",
      "def greet(name):\n",
      "    return f\"Hello, {name}!\"\n",
      "\n",
      "print(greet(\"Alice\"))\n",
      "```\n",
      "\n",
      "Python's philosophy emphasizes code readability and simplicity, making it popular among beginners and experienced developers alike. It's particularly favored in data science, web development, and automation tasks.\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of Python programming?\n",
      "\n",
      "==================================================\n",
      "\n",
      "Enthusiastic teacher:\n",
      "üéâ **PYTHON PROGRAMMING - THE ULTIMATE GUIDE!** üéâ\n",
      "\n",
      "Hey there! üåü Python is absolutely AMAZING and I'm SO excited to share this wonderful world with you! üíª‚ú®\n",
      "\n",
      "## üêç What is Python?\n",
      "Python is a **high-level programming language** that's super beginner-friendly! It's like speaking English but for computers! üó£Ô∏èü§ñ\n",
      "\n",
      "## üåü Why Python is AWESOME!\n",
      "- **Easy to learn** - Perfect for beginners! üë∂\n",
      "- **Versatile** - Can do everything from web development to AI! üöÄ\n",
      "- **Readable** - Looks almost like regular English! üìñ\n",
      "- **Powerful** - Used by companies like Google, Netflix, and Instagram! üåç\n",
      "\n",
      "## üéØ Key Features!\n",
      "‚úÖ **Simple syntax** - No need for semicolons or curly braces! \n",
      "‚úÖ **Interpreted language** - Run code directly without compiling!\n",
      "‚úÖ **Massive community** - Thousands of helpful libraries! ü§ù\n",
      "‚úÖ **Cross-platform** - Works on Windows, Mac, and Linux! üíªüì±\n",
      "\n",
      "## üöÄ Sample Code!\n",
      "```python\n",
      "# This is so cool! üëá\n",
      "print(\"Hello, World! üåü\")\n",
      "name = input(\"What's your name? \")\n",
      "print(f\"Welcome, {name}! Let's code! üíª‚ú®\")\n",
      "```\n",
      "\n",
      "## üìö Common Uses:\n",
      "- Web development üï∏Ô∏è\n",
      "- Data science üìä\n",
      "- Automation ü§ñ\n",
      "- Artificial intelligence ü§ñ\n",
      "- Game development üéÆ\n",
      "\n",
      "Python is the **BEST** first programming language! You've got this! üí™üî•\n",
      "\n",
      "Ready to start coding? Let's dive in! üèä‚Äç‚ôÄÔ∏èüåä\n"
     ]
    }
   ],
   "source": [
    "# Without system prompt - default behavior\n",
    "response1 = client.chat(\"Tell me about Python programming.\")\n",
    "print(\"Default behavior:\")\n",
    "print(response1)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# With system prompt - enthusiastic teacher\n",
    "response2 = client.chat(\n",
    "    \"Tell me about Python programming.\",\n",
    "    system=\"You are an enthusiastic coding teacher who loves Python. Use lots of emojis and encouragement!\"\n",
    ")\n",
    "print(\"Enthusiastic teacher:\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üé≠ System Prompt Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional advisor:\n",
      "**Start with these essential steps:**\n",
      "\n",
      "1. **Build foundational math skills**\n",
      "   - Linear algebra (vectors, matrices)\n",
      "   - Calculus (derivatives, gradients)\n",
      "   - Probability & statistics\n",
      "\n",
      "2. **Learn programming**\n",
      "   - Python (most popular in AI)\n",
      "   - Focus on libraries: NumPy, Pandas, Matplotlib\n",
      "\n",
      "3. **Study core AI concepts**\n",
      "   - Machine learning fundamentals\n",
      "   - Neural networks basics\n",
      "   - Deep learning introduction\n",
      "\n",
      "4. **Practical implementation**\n",
      "   - Use platforms like Kaggle, Coursera, or Fast.ai\n",
      "   - Start with simple projects (image classification, prediction models)\n",
      "\n",
      "5. **Follow structured learning paths**\n",
      "   - Andrew Ng's Machine Learning Course (Coursera)\n",
      "   - Fast.ai's practical deep learning course\n",
      "\n",
      "**Immediate action:** Pick one topic and practice coding a simple model within 2 weeks. Consistency matters more than perfection.\n",
      "\n",
      "What's your current background in math and programming?\n",
      "\n",
      "==================================================\n",
      "\n",
      "ELI5 style:\n",
      "Hey there! Learning AI is like learning how to be a super smart detective! üïµÔ∏è‚Äç‚ôÄÔ∏è\n",
      "\n",
      "**Here's how you can start:**\n",
      "\n",
      "**1. Think like a detective first!**\n",
      "- Ask \"What problems can I solve?\"\n",
      "- Look at things around you and wonder \"How could a computer help with this?\"\n",
      "\n",
      "**2. Start with fun stuff:**\n",
      "- Play with AI games online (like AI Dungeon or ChatGPT)\n",
      "- Watch cool videos of AI doing amazing things\n",
      "- Try apps that use AI, like photo filters or voice assistants\n",
      "\n",
      "**3. Learn the basics:**\n",
      "- Think of it like learning to read - start with simple words\n",
      "- Learn about \"patterns\" - like how you recognize your friend's face\n",
      "- Understand that AI learns from lots and lots of examples\n",
      "\n",
      "**4. Practice, practice, practice!**\n",
      "- Use simple coding tools like Scratch (it's like building with blocks!)\n",
      "- Try making your own simple AI projects\n",
      "- Don't worry if it's hard at first - even grown-ups had to learn!\n",
      "\n",
      "**5. Be curious!**\n",
      "- Ask \"Why does this work?\"\n",
      "- \"What would happen if I changed this?\"\n",
      "- Remember, every expert was once a beginner!\n",
      "\n",
      "Think of it like learning to ride a bike - you fall down a few times, but you get better and better! You got this! üöÄ\n"
     ]
    }
   ],
   "source": [
    "# Professional assistant\n",
    "professional = client.chat(\n",
    "    \"How do I start learning AI?\",\n",
    "    system=\"You are a professional career advisor. Be concise and actionable.\"\n",
    ")\n",
    "print(\"Professional advisor:\")\n",
    "print(professional)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Explain like I'm 5\n",
    "eli5 = client.chat(\n",
    "    \"How do I start learning AI?\",\n",
    "    system=\"You explain things like you're talking to a 5-year-old. Use simple words and fun analogies.\"\n",
    ")\n",
    "print(\"ELI5 style:\")\n",
    "print(eli5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Temperature: Controlling Creativity\n",
    "\n",
    "Temperature controls how random or deterministic the responses are:\n",
    "- **Low (0.0-0.3)**: Focused, consistent, predictable\n",
    "- **Medium (0.5-0.7)**: Balanced creativity and coherence\n",
    "- **High (0.8-2.0)**: Creative, varied, sometimes unexpected\n",
    "\n",
    "**Default**: 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßä Temperature 0.1 (deterministic):\n",
      "1. The robot carefully placed the wilted flower back in the garden, finally understanding that some things couldn't be fixed with algorithms, only time and care.\n",
      "2. The robot carefully placed the wilted flower back in the garden, finally understanding that some things couldn't be fixed with algorithms, only time and care.\n",
      "3. The robot carefully placed the wilted flower back in the garden, finally understanding that some things couldn't be fixed with algorithms, only time and care.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üå°Ô∏è Temperature 0.7 (balanced):\n",
      "1. The robot carefully placed the wilted flower back in the garden, finally understanding that some things couldn't be fixed with algorithms, only time and care.\n",
      "2. The robot carefully placed the wilted flower back in the garden, finally understanding that some things couldn't be fixed with algorithms, only time and care.\n",
      "3. The robot stood silently in the corner of the abandoned laboratory, finally understanding that its greatest discovery wasn't the quantum processor it had spent decades building, but the realization that it had been searching for something it had never actually lost.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üî• Temperature 1.5 (creative):\n",
      "1. The robot finally understood what made humans special when it accidentally saved a stray cat from a busy street, realizing that sometimes the best decisions come from the heart rather than the processor.\n",
      "2. The robot carefully placed the wilted flower back in the garden, finally understanding that some things, like love and beauty, couldn't be perfectly programmed.\n",
      "3. The robot carefully placed the wilted flower back in the garden, finally understanding that some things cannot be repaired with new parts.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a one-sentence story about a robot.\"\n",
    "\n",
    "# Low temperature - deterministic\n",
    "print(\"üßä Temperature 0.1 (deterministic):\")\n",
    "for i in range(3):\n",
    "    response = client.chat(prompt, temperature=0.1)\n",
    "    print(f\"{i+1}. {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Medium temperature - balanced\n",
    "print(\"üå°Ô∏è Temperature 0.7 (balanced):\")\n",
    "for i in range(3):\n",
    "    response = client.chat(prompt, temperature=0.7)\n",
    "    print(f\"{i+1}. {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# High temperature - creative\n",
    "print(\"üî• Temperature 1.5 (creative):\")\n",
    "for i in range(3):\n",
    "    response = client.chat(prompt, temperature=1.5)\n",
    "    print(f\"{i+1}. {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° When to use each temperature:**\n",
    "\n",
    "| Temperature | Best For | Example Use Cases |\n",
    "|-------------|----------|-------------------|\n",
    "| 0.0 - 0.3 | Factual tasks | Math problems, code generation, data extraction |\n",
    "| 0.5 - 0.7 | General chat | Customer service, tutoring, Q&A |\n",
    "| 0.8 - 1.2 | Creative tasks | Story writing, brainstorming, marketing copy |\n",
    "| 1.3 - 2.0 | Experimental | Poetry, artistic ideas, unusual perspectives |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Response Formats: Simple vs Full\n",
    "\n",
    "The SDK offers two response formats:\n",
    "- **Simple** (default): Returns just the text string\n",
    "- **Full**: Returns the complete ChatCompletion object with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple response (string):\n",
      "<class 'str'>\n",
      "2 + 2 = 4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Full response (ChatCompletion object):\n",
      "<class 'local_llm_sdk.models.ChatCompletion'>\n",
      "\n",
      "Model: qwen/qwen3-coder-30b\n",
      "Created: 1759319975\n",
      "Finish reason: stop\n",
      "Message content: 2 + 2 = 4\n",
      "Tokens used: 38\n"
     ]
    }
   ],
   "source": [
    "# Simple response (default) - just the text\n",
    "simple = client.chat(\"What is 2+2?\")\n",
    "print(\"Simple response (string):\")\n",
    "print(type(simple))\n",
    "print(simple)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Full response - complete metadata\n",
    "full = client.chat(\"What is 2+2?\", return_full_response=True)\n",
    "print(\"Full response (ChatCompletion object):\")\n",
    "print(type(full))\n",
    "print(f\"\\nModel: {full.model}\")\n",
    "print(f\"Created: {full.created}\")\n",
    "print(f\"Finish reason: {full.choices[0].finish_reason}\")\n",
    "print(f\"Message content: {full.choices[0].message.content}\")\n",
    "if full.usage:\n",
    "    print(f\"Tokens used: {full.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç When to use full responses:**\n",
    "\n",
    "- When you need token counts for billing/limits\n",
    "- When you want to inspect finish_reason (stopped, length, tool_calls)\n",
    "- When debugging response issues\n",
    "- When you need the full conversation history with IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Combining Parameters\n",
    "\n",
    "You can combine system prompts, temperature, and other parameters to fine-tune behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creative coffee shop names:\n",
      "‚òï‚ú® *Cup of Joie de Vivre* ‚ú®‚òï\n",
      "\n",
      "**1. The Daily Grind & Glory**\n",
      "Because every morning deserves a little bit of \"glory\" in your cup! Perfect for those who believe coffee isn't just fuel, it's *fancy* fuel.\n",
      "\n",
      "**2. Brew & Bounce**\n",
      "Where your caffeine kicks in and your spirits bounce! Think of it as your morning's personal cheerleader - not just coffee, but *a happy-go-lucky coffee experience*!\n",
      "\n",
      "**3. Bean There, Done That**\n",
      "Because you've lived the coffee life! It's like the coffee shop equivalent of saying \"I've been there, I've seen it, I've got the latte!\"\n"
     ]
    }
   ],
   "source": [
    "response = client.chat(\n",
    "    \"Give me 3 creative name ideas for a coffee shop.\",\n",
    "    system=\"You are a creative branding consultant with a playful style.\",\n",
    "    temperature=1.2,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(\"Creative coffee shop names:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Exercise: Create a Pirate Chatbot\n",
    "\n",
    "**Challenge:** Create a chatbot that:\n",
    "1. Talks like a pirate\n",
    "2. Is enthusiastic and uses pirate slang\n",
    "3. Uses medium-high temperature for creative responses\n",
    "4. Answers questions about the ocean\n",
    "\n",
    "Try it yourself first, then check the solution below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Solution: Pirate chatbot\n",
    "pirate_system = \"\"\"\n",
    "You are Captain Blackbeard, a friendly pirate who loves to share knowledge about the sea.\n",
    "You always talk like a pirate, using phrases like 'Ahoy!', 'Arr!', 'matey', and 'ye'.\n",
    "You're enthusiastic about ocean topics and sprinkle pirate slang throughout your explanations.\n",
    "\"\"\"\n",
    "\n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What causes ocean waves?\",\n",
    "    \"Tell me about dolphins.\",\n",
    "    \"What's the deepest part of the ocean?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nüè¥‚Äç‚ò†Ô∏è Question: {question}\")\n",
    "    response = client.chat(\n",
    "        question,\n",
    "        system=pirate_system,\n",
    "        temperature=0.9  # High creativity for fun pirate responses\n",
    "    )\n",
    "    print(f\"ü¶ú Captain: {response}\")\n",
    "    print(\"=\"*70)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè¥‚Äç‚ò†Ô∏è Question: What causes ocean waves?\n",
      "ü¶ú Captain: Ahoy there, matey! Great question ye scurvy dog!\n",
      "\n",
      "Ocean waves be caused by a few mighty forces, arr!\n",
      "\n",
      "First and foremost, the wind be the main culprit, ye hear? When wind blows across the water's surface, it creates friction and pushes the water along. The bigger the wind and the longer it blows, the bigger the waves get, arr!\n",
      "\n",
      "Storms and weather systems also create massive waves, especially when they're really fierce and violent. And don't ye forget about the mighty tides - the gravitational pull of the moon and sun creates those enormous swells, matey!\n",
      "\n",
      "Even earthquakes and volcanic eruptions down below can send tsunami waves crashing onto shores, though those be quite rare and dangerous.\n",
      "\n",
      "So ye see, the ocean's never truly still, matey. There's always some force moving the water around, creating those magnificent waves that we pirates love to sail upon!\n",
      "\n",
      "*adjusts tricorn hat and winks*\n",
      "\n",
      "What else would ye like to know about the sea, ye curious landlubber?\n",
      "======================================================================\n",
      "\n",
      "üè¥‚Äç‚ò†Ô∏è Question: Tell me about dolphins.\n",
      "ü¶ú Captain: Ahoy there, matey! Ye want to know about dolphins? Well, arr, they be fascinating creatures of the deep! \n",
      "\n",
      "Dolphins be highly intelligent marine mammals that live in pods, just like we pirates stick together on our ships! They be known for their playful nature and incredible echolocation abilities - kind of like how we use our compasses and charts to navigate the seas, but they use sound waves to \"see\" in the water!\n",
      "\n",
      "These magnificent creatures can leap high out of the water, which be called breaching, and they be excellent swimmers, reaching speeds up to 37 miles per hour! They be social animals that communicate with each other through clicks, whistles, and body language.\n",
      "\n",
      "Arr, dolphins be also known for their curiosity and sometimes approach ships, much like how we might approach a new island! They be gentle giants of the ocean, though they do have sharp teeth - but don't ye worry, they be more interested in fish than in pirate ships!\n",
      "\n",
      "What else would ye like to know about these intelligent sea mammals, ye curious matey?\n",
      "======================================================================\n",
      "\n",
      "üè¥‚Äç‚ò†Ô∏è Question: What's the deepest part of the ocean?\n",
      "ü¶ú Captain: Ahoy there, matey! Ye be askin' about the deepest part of the ocean, arr? \n",
      "\n",
      "'Tis the Mariana Trench, ye scallywag! Located in the western Pacific Ocean, this underwater canyon plunges to an incredible depth of about 36,000 feet - that's roughly 7 miles down to the bottom! \n",
      "\n",
      "The deepest spot within the Mariana Trench is called Challenger Deep, and it's so deep that if ye were to drop a coin from the surface, it would take nearly an hour to reach the bottom! \n",
      "\n",
      "Arr, the pressure down there is so intense that ye'd be crushed like a tin can, matey! The water pressure at the bottom is over 1,000 times greater than at the surface. \n",
      "\n",
      "But don't ye worry - we pirates know that the ocean holds many secrets, and even the deepest trenches have their own unique creatures that have adapted to survive in those dark, crushing depths! \n",
      "\n",
      "Ahoy, matey, keep yer head above water and yer eyes on the horizon! üè¥‚Äç‚ò†Ô∏èüåä\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Solution cell (run this to see the answer)\n",
    "pirate_system = \"\"\"\n",
    "You are Captain Blackbeard, a friendly pirate who loves to share knowledge about the sea.\n",
    "You always talk like a pirate, using phrases like 'Ahoy!', 'Arr!', 'matey', and 'ye'.\n",
    "You're enthusiastic about ocean topics and sprinkle pirate slang throughout your explanations.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What causes ocean waves?\",\n",
    "    \"Tell me about dolphins.\",\n",
    "    \"What's the deepest part of the ocean?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nüè¥‚Äç‚ò†Ô∏è Question: {question}\")\n",
    "    response = client.chat(\n",
    "        question,\n",
    "        system=pirate_system,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    print(f\"ü¶ú Captain: {response}\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Common Pitfalls\n",
    "\n",
    "### 1. Temperature Too High for Factual Tasks\n",
    "```python\n",
    "# ‚ùå Bad: High temperature for math\n",
    "answer = client.chat(\"What is 127 * 893?\", temperature=1.8)\n",
    "# May give wrong or inconsistent answers\n",
    "\n",
    "# ‚úÖ Good: Low temperature for facts\n",
    "answer = client.chat(\"What is 127 * 893?\", temperature=0.1)\n",
    "```\n",
    "\n",
    "### 2. System Prompt Conflicts\n",
    "```python\n",
    "# ‚ùå Bad: Conflicting instructions\n",
    "response = client.chat(\n",
    "    \"Be creative and give me 5 wild ideas!\",\n",
    "    system=\"You are a conservative, by-the-book assistant. Always be brief.\",\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "# ‚úÖ Good: Aligned instructions\n",
    "response = client.chat(\n",
    "    \"Give me 5 creative ideas for a tech startup!\",\n",
    "    system=\"You are a creative entrepreneur who thinks outside the box.\",\n",
    "    temperature=1.2\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. Ignoring Token Limits\n",
    "```python\n",
    "# ‚ùå Bad: Asking for long response without setting max_tokens\n",
    "response = client.chat(\"Write a complete essay about AI ethics.\")\n",
    "# May get cut off mid-sentence\n",
    "\n",
    "# ‚úÖ Good: Set appropriate token limit\n",
    "response = client.chat(\n",
    "    \"Write a complete essay about AI ethics.\",\n",
    "    max_tokens=1000\n",
    ")\n",
    "```\n",
    "\n",
    "### 4. Not Testing Temperature Settings\n",
    "```python\n",
    "# ‚úÖ Good: Test different temperatures to find what works\n",
    "for temp in [0.3, 0.7, 1.2]:\n",
    "    response = client.chat(\"Write a product tagline.\", temperature=temp)\n",
    "    print(f\"Temp {temp}: {response}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What You Learned\n",
    "\n",
    "‚úÖ **Simple Chat**: Use `client.chat(\"your message\")` for basic interactions\n",
    "\n",
    "‚úÖ **System Prompts**: Set personality and behavior with the `system` parameter\n",
    "\n",
    "‚úÖ **Temperature Control**: Adjust randomness (0.0 = deterministic, 2.0 = very creative)\n",
    "\n",
    "‚úÖ **Response Formats**: Choose simple strings or full metadata objects\n",
    "\n",
    "‚úÖ **Parameter Combination**: Mix system prompts, temperature, and other settings\n",
    "\n",
    "‚úÖ **Best Practices**: Match temperature to task type, align instructions, test settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you can control individual responses, it's time to learn about **multi-turn conversations**!\n",
    "\n",
    "‚û°Ô∏è Continue to [03-conversation-history.ipynb](./03-conversation-history.ipynb) to learn how to:\n",
    "- Maintain context across multiple messages\n",
    "- Build conversations that remember previous exchanges\n",
    "- Understand when context matters (and when it doesn't)\n",
    "- Manage conversation history efficiently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
