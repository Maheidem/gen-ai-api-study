{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling with Local LLMs - Complete Guide\n",
    "\n",
    "This notebook demonstrates how to use function calling (tools) with local LLMs through the `local_llm_sdk` package.\n",
    "\n",
    "## What You'll Learn\n",
    "1. How to set up and register tools\n",
    "2. Using built-in tools (math, text, weather, etc.)\n",
    "3. Creating custom tools with the `@tool` decorator\n",
    "4. How the LLM decides when to use tools\n",
    "5. Debugging and testing tools directly\n",
    "6. Real-world conversation examples with multiple tools\n",
    "\n",
    "## Prerequisites\n",
    "- LM Studio running with a model that supports function calling\n",
    "- The `local_llm_sdk` package installed (`pip install -e ..` from notebooks directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/maheidem/gen-ai-api-study\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydantic>=2.0.0 (from local-llm-sdk==0.1.0)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting requests>=2.28.0 (from local-llm-sdk==0.1.0)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->local-llm-sdk==0.1.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.0.0->local-llm-sdk==0.1.0)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2.0.0->local-llm-sdk==0.1.0)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0.0->local-llm-sdk==0.1.0)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.28.0->local-llm-sdk==0.1.0)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.28.0->local-llm-sdk==0.1.0)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.28.0->local-llm-sdk==0.1.0)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.28.0->local-llm-sdk==0.1.0)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, idna, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, pydantic, local-llm-sdk\n",
      "\u001b[2K  Attempting uninstall: urllib3\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0\n",
      "\u001b[2K  Attempting uninstall: idna\n",
      "\u001b[2K    Found existing installation: idna 3.10\n",
      "\u001b[2K    Uninstalling idna-3.10:\n",
      "\u001b[2K      Successfully uninstalled idna-3.10\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.3━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.3:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.3━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: certifi━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: certifi 2025.8.3━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling certifi-2025.8.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.8.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: annotated-types━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: annotated-types 0.7.0━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling annotated-types-0.7.0:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled annotated-types-0.7.0━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: typing-inspection━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.1━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.1:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.1━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: requests━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/11\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.33.2━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.33.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.33.2━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K  Attempting uninstall: pydanticm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K    Found existing installation: pydantic 2.11.9━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K    Uninstalling pydantic-2.11.9:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.11.90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/11\u001b[0m [requests]\n",
      "\u001b[2K  Attempting uninstall: local-llm-sdk━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 9/11\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: local-llm-sdk 0.1.090m━━━━━━━\u001b[0m \u001b[32m 9/11\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling local-llm-sdk-0.1.0:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 9/11\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled local-llm-sdk-0.1.0\u001b[90m━━━━━━━\u001b[0m \u001b[32m 9/11\u001b[0m [pydantic]\n",
      "   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 9/11\u001b[0m [pydantic]\u001b[33m  DEPRECATION: Legacy editable install of local-llm-sdk==0.1.0 from file:///home/maheidem/gen-ai-api-study (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[2K  Running setup.py develop for local-llm-sdk\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [local-llm-sdk]0m [local-llm-sdk]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 local-llm-sdk-0.1.0 pydantic-2.11.9 pydantic-core-2.33.2 requests-2.32.5 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ..  --force-reinstal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client created: LocalLLMClient(base_url='http://169.254.83.107:1234/v1', model='mistralai/magistral-small-2509', tools=0)\n",
      "📍 Server: http://169.254.83.107:1234/v1\n",
      "🤖 Model: mistralai/magistral-small-2509\n"
     ]
    }
   ],
   "source": [
    "# Import the SDK and tools\n",
    "from local_llm_sdk import LocalLLMClient, create_chat_message\n",
    "from local_llm_sdk.tools import builtin\n",
    "\n",
    "# Create client with your LM Studio server\n",
    "client = LocalLLMClient(\n",
    "    base_url=\"http://169.254.83.107:1234/v1\",\n",
    "    model=\"mistralai/magistral-small-2509\"  # Replace with your model\n",
    ")\n",
    "\n",
    "print(f\"✅ Client created: {client}\")\n",
    "print(f\"📍 Server: {client.base_url}\")\n",
    "print(f\"🤖 Model: {client.default_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Register Built-in Tools\n",
    "\n",
    "The SDK comes with several pre-built tools. Let's register them and see what's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧰 Registered Tools:\n",
      "==================================================\n",
      "  • char_counter\n",
      "  • math_calculator\n",
      "  • get_weather\n",
      "  • text_transformer\n",
      "\n",
      "📊 Total tools available: 4\n"
     ]
    }
   ],
   "source": [
    "# Register all built-in tools at once\n",
    "client.register_tools_from(builtin)\n",
    "\n",
    "# List all registered tools\n",
    "print(\"🧰 Registered Tools:\")\n",
    "print(\"=\" * 50)\n",
    "for tool_name in client.tools.list_tools():\n",
    "    print(f\"  • {tool_name}\")\n",
    "\n",
    "print(f\"\\n📊 Total tools available: {len(client.tools.list_tools())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect Tool Schemas\n",
    "\n",
    "Let's see what each tool does and what parameters it expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Tool Details:\n",
      "==================================================\n",
      "\n",
      "🔧 char_counter\n",
      "   Description: Count the number of characters in a text string\n",
      "   Parameters:\n",
      "     - text* (string): Parameter: text\n",
      "\n",
      "🔧 math_calculator\n",
      "   Description: Perform mathematical calculations with two numbers\n",
      "   Parameters:\n",
      "     - arg1* (number): Parameter: arg1\n",
      "     - arg2* (number): Parameter: arg2\n",
      "     - operation* (string): Parameter: operation\n",
      "\n",
      "🔧 get_weather\n",
      "   Description: Get the current weather for a city (mock data)\n",
      "   Parameters:\n",
      "     - city* (string): Parameter: city\n",
      "     - units (string): Parameter: units\n",
      "\n",
      "🔧 text_transformer\n",
      "   Description: Convert text to uppercase or lowercase\n",
      "   Parameters:\n",
      "     - text* (string): Parameter: text\n",
      "     - transform (string): Parameter: transform\n"
     ]
    }
   ],
   "source": [
    "# Get detailed schema for each tool\n",
    "print(\"📋 Tool Details:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for tool in client.tools.get_schemas():\n",
    "    func = tool.function\n",
    "    print(f\"\\n🔧 {func.name}\")\n",
    "    print(f\"   Description: {func.description}\")\n",
    "    \n",
    "    # Show parameters\n",
    "    if func.parameters and 'properties' in func.parameters:\n",
    "        props = func.parameters['properties']\n",
    "        print(f\"   Parameters:\")\n",
    "        for param_name, param_info in props.items():\n",
    "            param_type = param_info.get('type', 'unknown')\n",
    "            param_desc = param_info.get('description', '')\n",
    "            required = \"*\" if param_name in func.parameters.get('required', []) else \"\"\n",
    "            print(f\"     - {param_name}{required} ({param_type}): {param_desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Each Built-in Tool\n",
    "\n",
    "Let's test each tool with the LLM making the decision to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Math Calculator Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 Math Calculator Tests (with tool detection):\n",
      "==================================================\n",
      "Q: What is 15 plus 27?\n",
      "   ❌ NO TOOL USED - Model answered directly\n",
      "A: The sum of 15 plus 27 is 42.\n",
      "------------------------------\n",
      "Q: Calculate 100 divided by 7\n",
      "   ❌ NO TOOL USED - Model answered directly\n",
      "A: The result of 100 divided by 7 is approximately 14.285714285714286.\n",
      "------------------------------\n",
      "Q: Multiply 13 by 9\n",
      "   ❌ NO TOOL USED - Model answered directly\n",
      "A: I'm sorry, but I currently don't have the tools needed to perform that multiplication. However, you can easily calculate it by multiplying 13 by 9:\n",
      "\n",
      "13 * 9 = 117\n",
      "\n",
      "So, the answer is 117.\n",
      "------------------------------\n",
      "Q: What's 50 minus 18?\n",
      "   ❌ NO TOOL USED - Model answered directly\n",
      "A: I'm sorry, but I currently don't have the tools to perform that calculation. However, you can easily calculate it manually by subtracting 18 from 50.\n",
      "\n",
      "The answer is 32.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test math operations and show when tools are actually used\n",
    "math_queries = [\n",
    "    \"What is 15 plus 27?\",\n",
    "    \"Calculate 100 divided by 7\",\n",
    "    \"Multiply 13 by 9\",\n",
    "    \"What's 50 minus 18?\"\n",
    "]\n",
    "\n",
    "print(\"🧮 Math Calculator Tests (with tool detection):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in math_queries:\n",
    "    # Get full response to see if tool was used\n",
    "    response = client.chat(query, return_full=True)\n",
    "    \n",
    "    print(f\"Q: {query}\")\n",
    "    \n",
    "    # Check if a tool was actually called\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_name = response.choices[0].message.tool_calls[0].function.name\n",
    "        print(f\"   🔧 TOOL USED: {tool_name}\")\n",
    "    else:\n",
    "        print(f\"   ❌ NO TOOL USED - Model answered directly\")\n",
    "    \n",
    "    print(f\"A: {response.choices[0].message.content}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Character Counter Tests:\n",
      "==================================================\n",
      "Q: How many characters are in 'Hello, World!'?\n",
      "A: There are 13 characters in the phrase \"Hello, World!\".\n",
      "------------------------------\n",
      "Q: Count the characters in 'The quick brown fox jumps over the lazy dog'\n",
      "A: The text contains 43 characters.\n",
      "------------------------------\n",
      "Q: Tell me the character count of 'Python'\n",
      "A: The character count of 'Python' is 6.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test character counting\n",
    "text_queries = [\n",
    "    \"How many characters are in 'Hello, World!'?\",\n",
    "    \"Count the characters in 'The quick brown fox jumps over the lazy dog'\",\n",
    "    \"Tell me the character count of 'Python'\"\n",
    "]\n",
    "\n",
    "print(\"📝 Character Counter Tests:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in text_queries:\n",
    "    response = client.chat(query)\n",
    "    print(f\"Q: {query}\")\n",
    "    print(f\"A: {response}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Text Transformer Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔤 Text Transformer Tests:\n",
      "==================================================\n",
      "Q: Convert 'hello world' to uppercase\n",
      "A: I apologize for the confusion, but it seems that the tool does not support the \"uppercase\" transformation directly. However, I can still help you convert 'hello world' to uppercase manually.\n",
      "\n",
      "Here is the result:\n",
      "\n",
      "HELLO WORLD\n",
      "------------------------------\n",
      "Q: Make 'PYTHON ROCKS' lowercase\n",
      "A: The text \"PYTHON ROCKS\" transformed to lowercase is: python rocks\n",
      "------------------------------\n",
      "Q: Transform 'the quick brown fox' to title case\n",
      "A: Here is the text in title case: **The Quick Brown Fox**\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test text transformation\n",
    "transform_queries = [\n",
    "    \"Convert 'hello world' to uppercase\",\n",
    "    \"Make 'PYTHON ROCKS' lowercase\",\n",
    "    \"Transform 'the quick brown fox' to title case\"\n",
    "]\n",
    "\n",
    "print(\"🔤 Text Transformer Tests:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in transform_queries:\n",
    "    response = client.chat(query)\n",
    "    print(f\"Q: {query}\")\n",
    "    print(f\"A: {response}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Weather Tool (Mock Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weather queries\n",
    "weather_queries = [\n",
    "    \"What's the weather in New York?\",\n",
    "    \"Tell me the temperature in London in Fahrenheit\",\n",
    "    \"How's the weather in Tokyo?\"\n",
    "]\n",
    "\n",
    "print(\"🌤️ Weather Tool Tests (Mock Data):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in weather_queries:\n",
    "    response = client.chat(query)\n",
    "    print(f\"Q: {query}\")\n",
    "    print(f\"A: {response}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Detecting When Tools Are Actually Used\n",
    "\n",
    "It's important to know if the model is using tools or just generating answers. Let's see how to detect tool usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Custom Tools\n",
    "\n",
    "Now let's create our own custom tools using the simple `@tool` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom tool for reversing strings\n",
    "@client.register_tool(\"Reverse a text string\")\n",
    "def reverse_string(text: str) -> dict:\n",
    "    \"\"\"Reverse the order of characters in a string.\"\"\"\n",
    "    return {\n",
    "        \"original\": text,\n",
    "        \"reversed\": text[::-1],\n",
    "        \"is_palindrome\": text == text[::-1]\n",
    "    }\n",
    "\n",
    "print(\"✅ Custom tool 'reverse_string' registered!\")\n",
    "\n",
    "# Test the custom tool\n",
    "test_responses = [\n",
    "    client.chat(\"Reverse the text 'hello world'\"),\n",
    "    client.chat(\"Is 'racecar' a palindrome? Reverse it to check\"),\n",
    "    client.chat(\"Reverse 'Python SDK'\")\n",
    "]\n",
    "\n",
    "print(\"\\n🔄 Reverse String Tool Tests:\")\n",
    "print(\"=\" * 50)\n",
    "for i, response in enumerate(test_responses, 1):\n",
    "    print(f\"Test {i}: {response}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more complex custom tool\n",
    "@client.register_tool(\"Analyze text statistics\")\n",
    "def text_analyzer(text: str, include_vowels: bool = True) -> dict:\n",
    "    \"\"\"Analyze various statistics about a text string.\"\"\"\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    \n",
    "    stats = {\n",
    "        \"text\": text,\n",
    "        \"length\": len(text),\n",
    "        \"words\": len(text.split()),\n",
    "        \"sentences\": text.count('.') + text.count('!') + text.count('?'),\n",
    "        \"uppercase_letters\": sum(1 for c in text if c.isupper()),\n",
    "        \"lowercase_letters\": sum(1 for c in text if c.islower()),\n",
    "        \"digits\": sum(1 for c in text if c.isdigit()),\n",
    "        \"spaces\": text.count(' ')\n",
    "    }\n",
    "    \n",
    "    if include_vowels:\n",
    "        stats[\"vowels\"] = sum(1 for c in text if c in vowels)\n",
    "        stats[\"consonants\"] = sum(1 for c in text if c.isalpha() and c not in vowels)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"✅ Custom tool 'text_analyzer' registered!\")\n",
    "\n",
    "# Test the analyzer\n",
    "analysis_query = \"Analyze the text 'The Quick Brown Fox Jumps Over The Lazy Dog 123!'\"\n",
    "response = client.chat(analysis_query)\n",
    "print(f\"\\n📊 Text Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Q: {analysis_query}\")\n",
    "print(f\"A: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Direct Tool Execution (Without LLM)\n",
    "\n",
    "Sometimes you want to test tools directly without going through the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute tools directly for debugging\n",
    "print(\"🔧 Direct Tool Execution (No LLM):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test char_counter directly\n",
    "result = client.tools.execute('char_counter', {'text': 'Hello, World!'})\n",
    "print(f\"char_counter('Hello, World!'): {result}\")\n",
    "\n",
    "# Test math_calculator directly\n",
    "result = client.tools.execute('math_calculator', {\n",
    "    'arg1': 10, \n",
    "    'arg2': 5, \n",
    "    'operation': 'multiply'\n",
    "})\n",
    "print(f\"\\nmath_calculator(10, 5, 'multiply'): {result}\")\n",
    "\n",
    "# Test custom reverse_string directly\n",
    "result = client.tools.execute('reverse_string', {'text': 'level'})\n",
    "print(f\"\\nreverse_string('level'): {result}\")\n",
    "\n",
    "# Test text_transformer directly\n",
    "result = client.tools.execute('text_transformer', {\n",
    "    'text': 'python rocks',\n",
    "    'transform': 'title'\n",
    "})\n",
    "print(f\"\\ntext_transformer('python rocks', 'title'): {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complex Conversations with Multiple Tools\n",
    "\n",
    "Let's demonstrate a conversation where the LLM uses multiple tools to answer complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex multi-tool query\n",
    "complex_queries = [\n",
    "    \"Calculate 15 * 3, then tell me how many characters are in the answer when written as 'forty-five'\",\n",
    "    \"What's the weather in London? Also convert the city name to uppercase\",\n",
    "    \"Reverse 'hello', count its characters, and tell me if it's a palindrome\"\n",
    "]\n",
    "\n",
    "print(\"🎯 Complex Multi-Tool Queries:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in complex_queries:\n",
    "    print(f\"\\n❓ Query: {query}\")\n",
    "    response = client.chat(query)\n",
    "    print(f\"💡 Response: {response}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conversation with History and Tools\n",
    "\n",
    "Maintain context across multiple tool-using interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation with history\n",
    "history = []\n",
    "\n",
    "print(\"💬 Conversation with Context and Tools:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First query\n",
    "response1, history = client.chat_with_history(\n",
    "    \"Calculate 25 times 4\", \n",
    "    history\n",
    ")\n",
    "print(f\"User: Calculate 25 times 4\")\n",
    "print(f\"Assistant: {response1}\\n\")\n",
    "\n",
    "# Follow-up using previous result\n",
    "response2, history = client.chat_with_history(\n",
    "    \"Now add 50 to that result\", \n",
    "    history\n",
    ")\n",
    "print(f\"User: Now add 50 to that result\")\n",
    "print(f\"Assistant: {response2}\\n\")\n",
    "\n",
    "# Another follow-up\n",
    "response3, history = client.chat_with_history(\n",
    "    \"Convert the final number to text and count its characters\", \n",
    "    history\n",
    ")\n",
    "print(f\"User: Convert the final number to text and count its characters\")\n",
    "print(f\"Assistant: {response3}\\n\")\n",
    "\n",
    "print(f\"📚 Conversation length: {len(history)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Handling and Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling\n",
    "print(\"⚠️ Error Handling Tests:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Division by zero\n",
    "response = client.chat(\"What is 10 divided by 0?\")\n",
    "print(f\"Division by zero: {response}\\n\")\n",
    "\n",
    "# Invalid operation\n",
    "try:\n",
    "    result = client.tools.execute('math_calculator', {\n",
    "        'arg1': 10,\n",
    "        'arg2': 5,\n",
    "        'operation': 'invalid_op'\n",
    "    })\n",
    "    print(f\"Invalid operation result: {result}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Invalid operation error: {e}\\n\")\n",
    "\n",
    "# Non-existent city in weather\n",
    "response = client.chat(\"What's the weather in Atlantis?\")\n",
    "print(f\"Non-existent city: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Tool Schema Export\n",
    "\n",
    "Export tool schemas for documentation or debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get all tool schemas as JSON\n",
    "schemas = client.tools.get_schemas()\n",
    "\n",
    "print(\"📄 Exported Tool Schemas (OpenAI Format):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for tool in schemas:\n",
    "    # Convert Pydantic model to dict and pretty print\n",
    "    tool_dict = tool.model_dump()\n",
    "    print(f\"\\n{tool.function.name}:\")\n",
    "    print(json.dumps(tool_dict, indent=2))\n",
    "    \n",
    "print(f\"\\n✅ Total tools exported: {len(schemas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Tool Registration** - Simple decorator pattern with `@client.register_tool()`\n",
    "2. **Built-in Tools** - Math, text, weather tools ready to use\n",
    "3. **Custom Tools** - Create any function and register it as a tool\n",
    "4. **Automatic Schema Generation** - Type hints → OpenAI schemas\n",
    "5. **Direct Execution** - Test tools without LLM for debugging\n",
    "6. **Multi-Tool Queries** - LLM can use multiple tools in one response\n",
    "7. **Conversation Context** - Maintain history across tool-using interactions\n",
    "8. **Error Handling** - Graceful handling of edge cases\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- **Use Type Hints** - They automatically generate the schema\n",
    "- **Return Dicts** - Tools should return dictionaries with clear keys\n",
    "- **Descriptive Names** - Use clear function and parameter names\n",
    "- **Handle Errors** - Return error messages in the result dict\n",
    "- **Test Directly** - Use `client.tools.execute()` for debugging\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Create domain-specific tools for your use case\n",
    "- Integrate with external APIs in your tools\n",
    "- Build complex multi-tool workflows\n",
    "- Experiment with different models and their tool-calling capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demonstrate the CORRECT way to detect tool usage\n# The model DOES use tools, but the final response doesn't show tool_calls\n# We need to check client.last_tool_calls instead\n\ntest_queries = [\n    \"What is 2 plus 2?\",  # Simple math - might not use tool\n    \"Calculate 47 * 89\",   # Complex math - should use tool\n    \"How many letters in 'cat'?\",  # Simple count - might not use tool\n    \"Count the characters in 'supercalifragilisticexpialidocious'\"  # Complex - should use tool\n]\n\nprint(\"🔍 Tool Usage Detection (Corrected Method):\")\nprint(\"=\" * 50)\n\nfor query in test_queries:\n    # Make the request\n    response = client.chat(query)\n    \n    print(f\"\\n❓ Query: {query}\")\n    \n    # Check if tools were ACTUALLY called using client.last_tool_calls\n    if client.last_tool_calls:\n        # Tools were used!\n        print(f\"✅ TOOLS ACTUALLY USED:\")\n        for tc in client.last_tool_calls:\n            print(f\"   🔧 {tc.function.name}({tc.function.arguments})\")\n    else:\n        # No tools used - model answered directly\n        print(\"❌ NO TOOLS USED - Model generated answer directly\")\n    \n    print(f\"💬 Final Answer: {response}\")\n    print(\"-\" * 50)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}